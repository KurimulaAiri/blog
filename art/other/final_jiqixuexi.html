<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.24" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.94" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"机器学习选择题","image":[""],"datePublished":"2025-06-17T00:00:00.000Z","dateModified":"2025-06-17T09:36:40.000Z","author":[{"@type":"Person","name":"KurimulaAiri","url":"https://github.com/KurimulaAiri"}]}</script><meta property="og:url" content="https://md.s1r0ko.top/art/other/final_jiqixuexi.html"><meta property="og:site_name" content="博客与资料库"><meta property="og:title" content="机器学习选择题"><meta property="og:description" content="期末随堂测试-数科22级 1.(判断题) 使用k-means算法聚类，算法执行过程中有可能出现空簇。 答案: 对 错 2.(判断题) 基于密度的聚类方法DBSCAN无需指定簇的个数。 答案: 对 错 3.(判断题) 使用基于密度的聚类方法DBSCAN后，每个样本都会归到某个簇中。 答案: 对 错 4.(判断题) 使用基于凝聚的层次聚类算法AGNES聚类..."><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-06-17T09:36:40.000Z"><meta property="article:tag" content="机器学习"><meta property="article:published_time" content="2025-06-17T00:00:00.000Z"><meta property="article:modified_time" content="2025-06-17T09:36:40.000Z"><link rel="icon" href="/favicon.ico"><title>机器学习选择题 | 博客与资料库</title><meta name="description" content="期末随堂测试-数科22级 1.(判断题) 使用k-means算法聚类，算法执行过程中有可能出现空簇。 答案: 对 错 2.(判断题) 基于密度的聚类方法DBSCAN无需指定簇的个数。 答案: 对 错 3.(判断题) 使用基于密度的聚类方法DBSCAN后，每个样本都会归到某个簇中。 答案: 对 错 4.(判断题) 使用基于凝聚的层次聚类算法AGNES聚类...">
    <link rel="preload" href="/assets/style-D-SUM40f.css" as="style"><link rel="stylesheet" href="/assets/style-D-SUM40f.css">
    <link rel="modulepreload" href="/assets/app-C0fdAW9E.js"><link rel="modulepreload" href="/assets/final_jiqixuexi.html-C-kMuJSn.js">
    <link rel="prefetch" href="/assets/index.html-Bq9OjVWF.js" as="script"><link rel="prefetch" href="/assets/intro.html-C1Xil6nW.js" as="script"><link rel="prefetch" href="/assets/Memorandum.html-DT4clELS.js" as="script"><link rel="prefetch" href="/assets/index.html-DhaWeG71.js" as="script"><link rel="prefetch" href="/assets/index.html-BTfXIg8l.js" as="script"><link rel="prefetch" href="/assets/intro.html-BOxFr1zD.js" as="script"><link rel="prefetch" href="/assets/index.html-B--ecy5P.js" as="script"><link rel="prefetch" href="/assets/C.html-CLyJ7lrG.js" as="script"><link rel="prefetch" href="/assets/LaTex.html-BzR363fi.js" as="script"><link rel="prefetch" href="/assets/index.html-DYqE7fYh.js" as="script"><link rel="prefetch" href="/assets/Test.html-B1bfjnrc.js" as="script"><link rel="prefetch" href="/assets/final_jiwang.html-CA_TwRCx.js" as="script"><link rel="prefetch" href="/assets/jiqixuexibiji.html-BQcwJdhY.js" as="script"><link rel="prefetch" href="/assets/secret.html-u1B9g4FF.js" as="script"><link rel="prefetch" href="/assets/index.html-DMoKodqC.js" as="script"><link rel="prefetch" href="/assets/disable.html-BxCY2sky.js" as="script"><link rel="prefetch" href="/assets/encrypt.html-XawGr8aZ.js" as="script"><link rel="prefetch" href="/assets/layout.html-C7ioHFiJ.js" as="script"><link rel="prefetch" href="/assets/markdown.html-DZzB7lU7.js" as="script"><link rel="prefetch" href="/assets/page.html-Co0ffbMI.js" as="script"><link rel="prefetch" href="/assets/cherry.html-B5J5opD0.js" as="script"><link rel="prefetch" href="/assets/dragonfruit.html-CVaAZVZa.js" as="script"><link rel="prefetch" href="/assets/strawberry.html-DM4Rd_uD.js" as="script"><link rel="prefetch" href="/assets/tomato.html-C8BBE60f.js" as="script"><link rel="prefetch" href="/assets/Linux.html-BCUGIHZQ.js" as="script"><link rel="prefetch" href="/assets/index.html-BSU_ZHZE.js" as="script"><link rel="prefetch" href="/assets/1.html-BzbzLD8S.js" as="script"><link rel="prefetch" href="/assets/2.html-uSqYirhO.js" as="script"><link rel="prefetch" href="/assets/3.html-BbP8GCa5.js" as="script"><link rel="prefetch" href="/assets/index.html-rTFbn8Z9.js" as="script"><link rel="prefetch" href="/assets/index.html-DWBaW8ht.js" as="script"><link rel="prefetch" href="/assets/1.html-D_-xi_0G.js" as="script"><link rel="prefetch" href="/assets/2.html-C6l51GQU.js" as="script"><link rel="prefetch" href="/assets/3.html-DfvD5TVG.js" as="script"><link rel="prefetch" href="/assets/4.html-BjybBEuA.js" as="script"><link rel="prefetch" href="/assets/1.html-CC4cfucA.js" as="script"><link rel="prefetch" href="/assets/2.html-mt4wBB7w.js" as="script"><link rel="prefetch" href="/assets/3.html-Bn1IlY7k.js" as="script"><link rel="prefetch" href="/assets/4.html-CxNZSt4t.js" as="script"><link rel="prefetch" href="/assets/index.html-NKa7vAII.js" as="script"><link rel="prefetch" href="/assets/index.html-pEHYfZGx.js" as="script"><link rel="prefetch" href="/assets/index.html-D_RH5NgG.js" as="script"><link rel="prefetch" href="/assets/index.html-CEKXPpx8.js" as="script"><link rel="prefetch" href="/assets/other.html-DwmOhrxb.js" as="script"><link rel="prefetch" href="/assets/index.html-C-mj1v9b.js" as="script"><link rel="prefetch" href="/assets/index.html-Cz2P-m4N.js" as="script"><link rel="prefetch" href="/assets/index.html-Bv75BCiK.js" as="script"><link rel="prefetch" href="/assets/index.html-DlU5CxtX.js" as="script"><link rel="prefetch" href="/assets/Lessen.html-D8sJ4-iz.js" as="script"><link rel="prefetch" href="/assets/index.html-4WUAudXj.js" as="script"><link rel="prefetch" href="/assets/RocketMQ.html-B2EV0IId.js" as="script"><link rel="prefetch" href="/assets/ApplicationLayer.html-fJYoLmUn.js" as="script"><link rel="prefetch" href="/assets/ClassificationOfComputerNetworks.html-CINQxs1G.js" as="script"><link rel="prefetch" href="/assets/CodingAndModulation.html-CYdnCozn.js" as="script"><link rel="prefetch" href="/assets/ErrorCorrectionCoding.html-Bi4nMWEv.js" as="script"><link rel="prefetch" href="/assets/EthernetSwitches.html-CFHpKr8X.js" as="script"><link rel="prefetch" href="/assets/FlowControlForReliableTransmission.html-CIeCnsLp.js" as="script"><link rel="prefetch" href="/assets/Framing.html-cglG1ZNf.js" as="script"><link rel="prefetch" href="/assets/FunctionalityOfTheDataLinkLayer.html-CqdFRH_h.js" as="script"><link rel="prefetch" href="/assets/FunctionalityOfTheNetworkLayer.html-CL4ZN525.js" as="script"><link rel="prefetch" href="/assets/HierarchicalStructure.html-0yFxmrT8.js" as="script"><link rel="prefetch" href="/assets/IPv4.html-Cc5-pETy.js" as="script"><link rel="prefetch" href="/assets/IPv6.html-DgIiDQSN.js" as="script"><link rel="prefetch" href="/assets/LocalAreaNetwork.html-CDHhqPGQ.js" as="script"><link rel="prefetch" href="/assets/MediaAccessControl.html-LVL960J9.js" as="script"><link rel="prefetch" href="/assets/OSIModel.html-F2uuRIP4.js" as="script"><link rel="prefetch" href="/assets/Overview.html-DtLcDDhx.js" as="script"><link rel="prefetch" href="/assets/PerformanceMetricsForComputerNetworks.html-CAXNE1Fq.js" as="script"><link rel="prefetch" href="/assets/PhysicalLayerDevices.html-Bv5_Ivc1.js" as="script"><link rel="prefetch" href="/assets/index.html-U0_7xzVJ.js" as="script"><link rel="prefetch" href="/assets/RoutingAlgorithmsAndRoutingProtocols.html-CXNWb7mA.js" as="script"><link rel="prefetch" href="/assets/ServicesProvidedByTheTransportLayer.html-DM1r4WVD.js" as="script"><link rel="prefetch" href="/assets/TCP_IPModel.html-B4Rl2T_I.js" as="script"><link rel="prefetch" href="/assets/TheBasicConceptOfCommunication.html-C9G5zqvu.js" as="script"><link rel="prefetch" href="/assets/TheCompositionAndFunctionsOfComputerNetworks.html-kj8yFTf7.js" as="script"><link rel="prefetch" href="/assets/ThreeWaysOfExchange.html-dkjCnjqG.js" as="script"><link rel="prefetch" href="/assets/TransmissionMedium.html-BCj4YlPg.js" as="script"><link rel="prefetch" href="/assets/Algorithm.html-Bc58yLYu.js" as="script"><link rel="prefetch" href="/assets/LinearList_1.html-DVpJntHx.js" as="script"><link rel="prefetch" href="/assets/LinearList_2.html-CMfh5mpy.js" as="script"><link rel="prefetch" href="/assets/OverviewOfDataStructures.html-COMpNrPl.js" as="script"><link rel="prefetch" href="/assets/Queue.html-DD2jhAPe.js" as="script"><link rel="prefetch" href="/assets/index.html-CgS7o3Gr.js" as="script"><link rel="prefetch" href="/assets/Stack.html-l36sm-t-.js" as="script"><link rel="prefetch" href="/assets/ArchitectureOfTheOperatingSystem.html-e7j7rlAN.js" as="script"><link rel="prefetch" href="/assets/BootOfTheOperatingSystem.html-NsXd5gOo.js" as="script"><link rel="prefetch" href="/assets/CharacteristicsOfTheOperatingSystem.html-DQ0O_QC8.js" as="script"><link rel="prefetch" href="/assets/Deadlock.html-DlwNAgXA.js" as="script"><link rel="prefetch" href="/assets/DevelopmentAndClassificationOfOperatingSystems.html-CBnzw4Dj.js" as="script"><link rel="prefetch" href="/assets/InterruptionsAndExceptions.html-CEenTbkJ.js" as="script"><link rel="prefetch" href="/assets/Memory.html-DfuFCFpV.js" as="script"><link rel="prefetch" href="/assets/Overview.html-CtNHajkM.js" as="script"><link rel="prefetch" href="/assets/PipeProcess.html-mC-nQz86.js" as="script"><link rel="prefetch" href="/assets/Process.html-BRXu6vqi.js" as="script"><link rel="prefetch" href="/assets/ProcessSynchronizationAndMutualExclusion.html-BCTFAkVG.js" as="script"><link rel="prefetch" href="/assets/ProcessSynchronizationMutualExclusionRelatedIssues.html-DRgNpBl1.js" as="script"><link rel="prefetch" href="/assets/index.html-CzqConlf.js" as="script"><link rel="prefetch" href="/assets/Scheduling.html-BprH95HT.js" as="script"><link rel="prefetch" href="/assets/Signal.html-DY7JxYQB.js" as="script"><link rel="prefetch" href="/assets/SystemCall.html-CebUepUG.js" as="script"><link rel="prefetch" href="/assets/TheOperatingMechanismOfTheOperatingSystem.html-DHRAUUG3.js" as="script"><link rel="prefetch" href="/assets/Thread.html-CdpqXOEC.js" as="script"><link rel="prefetch" href="/assets/VirtualMachine.html-BN-5IXRi.js" as="script"><link rel="prefetch" href="/assets/CoordinateSystemAndItsTransformation.html-D2BZ0ngl.js" as="script"><link rel="prefetch" href="/assets/EquationsAndInequalities.html-H1D8mTO9.js" as="script"><link rel="prefetch" href="/assets/Function.html-B2OWNAzI.js" as="script"><link rel="prefetch" href="/assets/Overview.html-BJV7myuW.js" as="script"><link rel="prefetch" href="/assets/index.html-BiPJ5QO6.js" as="script"><link rel="prefetch" href="/assets/SequencesAndTheirMonotonicity.html-BfSSs48E.js" as="script"><link rel="prefetch" href="/assets/index.html-n5eFw435.js" as="script"><link rel="prefetch" href="/assets/404.html-Bw-HG3ey.js" as="script"><link rel="prefetch" href="/assets/index.html-DwXffd4L.js" as="script"><link rel="prefetch" href="/assets/index.html-DHBwkvL1.js" as="script"><link rel="prefetch" href="/assets/index.html-BndeTt5X.js" as="script"><link rel="prefetch" href="/assets/index.html-CYouIdMd.js" as="script"><link rel="prefetch" href="/assets/index.html-CKgui2is.js" as="script"><link rel="prefetch" href="/assets/index.html-CcvlwLr-.js" as="script"><link rel="prefetch" href="/assets/index.html-XCC4qZ4k.js" as="script"><link rel="prefetch" href="/assets/index.html-ICNiqEyj.js" as="script"><link rel="prefetch" href="/assets/index.html-ij_BVoIr.js" as="script"><link rel="prefetch" href="/assets/index.html-BMM528PI.js" as="script"><link rel="prefetch" href="/assets/index.html-B5n8SdyX.js" as="script"><link rel="prefetch" href="/assets/index.html-BijnCeqP.js" as="script"><link rel="prefetch" href="/assets/index.html-Cstf3M77.js" as="script"><link rel="prefetch" href="/assets/index.html-D2r2DUQM.js" as="script"><link rel="prefetch" href="/assets/index.html-Ruk4X1Mg.js" as="script"><link rel="prefetch" href="/assets/index.html-Dy8t274p.js" as="script"><link rel="prefetch" href="/assets/index.html-BiWQer-k.js" as="script"><link rel="prefetch" href="/assets/index.html-DEIK6wQg.js" as="script"><link rel="prefetch" href="/assets/index.html-DtTd5Zdp.js" as="script"><link rel="prefetch" href="/assets/index.html-rf7CIdyL.js" as="script"><link rel="prefetch" href="/assets/index.html-B5Wn5MeQ.js" as="script"><link rel="prefetch" href="/assets/index.html-nUTIHzTZ.js" as="script"><link rel="prefetch" href="/assets/index.html-BG2b69jq.js" as="script"><link rel="prefetch" href="/assets/index.html-B8syoS5B.js" as="script"><link rel="prefetch" href="/assets/index.html-DBQV1jqu.js" as="script"><link rel="prefetch" href="/assets/index.html-DBEPqHJq.js" as="script"><link rel="prefetch" href="/assets/index.html-DvXj9Aoi.js" as="script"><link rel="prefetch" href="/assets/index.html-Dja1Uoly.js" as="script"><link rel="prefetch" href="/assets/index.html-Ct6bDaFO.js" as="script"><link rel="prefetch" href="/assets/index.html-BJ4JbZNa.js" as="script"><link rel="prefetch" href="/assets/index.html-D9TDkNYB.js" as="script"><link rel="prefetch" href="/assets/index.html-CFUJ3zZ2.js" as="script"><link rel="prefetch" href="/assets/index.html-CLQpDGGh.js" as="script"><link rel="prefetch" href="/assets/index.html-CnMG7kVe.js" as="script"><link rel="prefetch" href="/assets/index.html-m-FmWPOS.js" as="script"><link rel="prefetch" href="/assets/index.html-B0F0WVEP.js" as="script"><link rel="prefetch" href="/assets/index.html-DeJ6MJZM.js" as="script"><link rel="prefetch" href="/assets/index.html-D8z57_6u.js" as="script"><link rel="prefetch" href="/assets/index.html-Bm6ZDg0X.js" as="script"><link rel="prefetch" href="/assets/index.html-BhsmbeFM.js" as="script"><link rel="prefetch" href="/assets/index.html-DqV4fid_.js" as="script"><link rel="prefetch" href="/assets/index.html-BIbD5dOs.js" as="script"><link rel="prefetch" href="/assets/index.html-DyDfR4TK.js" as="script"><link rel="prefetch" href="/assets/index.html-BzOwnlWt.js" as="script"><link rel="prefetch" href="/assets/index.html-BP5ASqTT.js" as="script"><link rel="prefetch" href="/assets/index.html-BaXvFWYL.js" as="script"><link rel="prefetch" href="/assets/index.html-BcdTHDWO.js" as="script"><link rel="prefetch" href="/assets/index.html-C6Vg_Oc0.js" as="script"><link rel="prefetch" href="/assets/index.html-ClMgvkHS.js" as="script"><link rel="prefetch" href="/assets/index.html-BdE4EvW9.js" as="script"><link rel="prefetch" href="/assets/index.html-D-j8j7OY.js" as="script"><link rel="prefetch" href="/assets/index.html-BrzmLqNp.js" as="script"><link rel="prefetch" href="/assets/index.html-Dn2NQOBo.js" as="script"><link rel="prefetch" href="/assets/index.html-BdE4EvW9.js" as="script"><link rel="prefetch" href="/assets/index.html-D5Ewefgi.js" as="script"><link rel="prefetch" href="/assets/index.html-CSBKeq_8.js" as="script"><link rel="prefetch" href="/assets/index.html-zHBhx8wh.js" as="script"><link rel="prefetch" href="/assets/index.html-CQqy1lr8.js" as="script"><link rel="prefetch" href="/assets/index.html-CzdedmTY.js" as="script"><link rel="prefetch" href="/assets/index.html-BGJJJPIT.js" as="script"><link rel="prefetch" href="/assets/index.html-BbH0RYMA.js" as="script"><link rel="prefetch" href="/assets/index.html-DJfoo_DV.js" as="script"><link rel="prefetch" href="/assets/index.html-DMAdhHK3.js" as="script"><link rel="prefetch" href="/assets/index.html-CWNdWGUK.js" as="script"><link rel="prefetch" href="/assets/index.html-DwwulMak.js" as="script"><link rel="prefetch" href="/assets/index.html-DhObLE4q.js" as="script"><link rel="prefetch" href="/assets/index.html-gUt7WFKV.js" as="script"><link rel="prefetch" href="/assets/index.html-Dl-Gbtq2.js" as="script"><link rel="prefetch" href="/assets/index.html-Wl_Vy8dE.js" as="script"><link rel="prefetch" href="/assets/index.html-NESpSS7a.js" as="script"><link rel="prefetch" href="/assets/index.html-C8mLyZ1g.js" as="script"><link rel="prefetch" href="/assets/index.html-DUF92Ne8.js" as="script"><link rel="prefetch" href="/assets/index.html-DDVrb029.js" as="script"><link rel="prefetch" href="/assets/index.html-B4GKaCYQ.js" as="script"><link rel="prefetch" href="/assets/index.html-CnsyO5xj.js" as="script"><link rel="prefetch" href="/assets/index.html-CKNqOSJw.js" as="script"><link rel="prefetch" href="/assets/index.html-DJgyBfks.js" as="script"><link rel="prefetch" href="/assets/index.html-DcgwiBV0.js" as="script"><link rel="prefetch" href="/assets/index.html-36YXb1v9.js" as="script"><link rel="prefetch" href="/assets/index.html-D8E05Fy_.js" as="script"><link rel="prefetch" href="/assets/index.html-BAztHFCS.js" as="script"><link rel="prefetch" href="/assets/index.html-D-4YtqGn.js" as="script"><link rel="prefetch" href="/assets/index-DeXEqRQP.js" as="script"><link rel="prefetch" href="/assets/index-BscV6lH7.js" as="script"><link rel="prefetch" href="/assets/index-Bh_txMi5.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-CKV1Bsxh.js" as="script"><link rel="prefetch" href="/assets/prod-B9rlLNUT.js" as="script"><link rel="prefetch" href="/assets/prod-B9rlLNUT.js" as="script"><link rel="prefetch" href="/assets/vidstack-audio-BdoTlpIG.js" as="script"><link rel="prefetch" href="/assets/vidstack-video-DvQL3hIW.js" as="script"><link rel="prefetch" href="/assets/vidstack-hls-C6jjUjHp.js" as="script"><link rel="prefetch" href="/assets/vidstack-dash-Bvz7H4t1.js" as="script"><link rel="prefetch" href="/assets/vidstack-vimeo-DqRb8KZm.js" as="script"><link rel="prefetch" href="/assets/vidstack-krOAtKMi-2f5gzOW6.js" as="script"><link rel="prefetch" href="/assets/vidstack-youtube-BXp4pq6C.js" as="script"><link rel="prefetch" href="/assets/vidstack-Dm1xEU9Q-DDN5V1NO.js" as="script"><link rel="prefetch" href="/assets/vidstack-D2pY00kU-QT5eduGe.js" as="script"><link rel="prefetch" href="/assets/vidstack-D_-9AA6_-DIf5oOJ0.js" as="script"><link rel="prefetch" href="/assets/vidstack-player-default-layout-4olN3Tz8.js" as="script"><link rel="prefetch" href="/assets/vidstack-player-ui-BnUvbF8n.js" as="script"><link rel="prefetch" href="/assets/vidstack-D3ltXc3a-BssF-_N0.js" as="script"><link rel="prefetch" href="/assets/giscus-DkdbftNg.js" as="script"><link rel="prefetch" href="/assets/index-J6HJWV42.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/" aria-label="带我回家"><img class="vp-nav-logo" src="/logo.png" alt><!----><span class="vp-site-name hide-in-pad">博客与资料库</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="KurimulaAiri的小窝"><!--[--><VPIcon icon="house" sizing="height"></VPIcon><!--]-->KurimulaAiri的小窝<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="文章"><!--[--><VPIcon icon="pen-to-square"></VPIcon>文章<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">代码学习</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/art/learning/coding/cy/stage_4/RocketMQ.html" aria-label="RocketMQ安装与配置"><!--[--><VPIcon icon="pen-to-square" sizing="both"></VPIcon><!--]-->RocketMQ安装与配置<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/art/learning/coding/cy/stage_4/Lessen.html" aria-label="四阶段笔记"><!--[--><VPIcon icon="pen-to-square" sizing="both"></VPIcon><!--]-->四阶段笔记<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">考研相关</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/art/learning/master/math/" aria-label="数学"><!--[--><VPIcon icon="pen-to-square" sizing="both"></VPIcon><!--]-->数学<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/art/learning/master/english/" aria-label="英语"><!--[--><VPIcon icon="pen-to-square" sizing="both"></VPIcon><!--]-->英语<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/art/learning/master/politics/" aria-label="政治"><!--[--><VPIcon icon="pen-to-square" sizing="both"></VPIcon><!--]-->政治<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/art/learning/master/major/" aria-label="专业课"><!--[--><VPIcon icon="pen-to-square" sizing="both"></VPIcon><!--]-->专业课<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">其他</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/art/other/LaTex.html" aria-label="Latex速查表"><!--[--><VPIcon icon="pen-to-square" sizing="both"></VPIcon><!--]-->Latex速查表<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/art/other/Test.html" aria-label="测试用"><!--[--><VPIcon icon="code" sizing="both"></VPIcon><!--]-->测试用<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/intro.html" aria-label="介绍页"><!--[--><VPIcon icon="circle-info" sizing="height"></VPIcon><!--]-->介绍页<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><div class="vp-nav-item"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="选择语言"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" name="i18n" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/art/other/final_jiqixuexi.html" aria-label="简体中文"><!---->简体中文<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/en/" aria-label="English"><!---->English<!----></a></li></ul></button></div></div><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/KurimulaAiri/blog" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-appearance-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon" name="outlook"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="vp-appearance-dropdown"><!----></div></button></div><!--[--><div id="docsearch-container" style="display:none;"></div><div><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索文档"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">搜索文档</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"><svg width="15" height="15" class="DocSearch-Control-Key-Icon"><path d="M4.505 4.496h2M5.505 5.496v5M8.216 4.496l.055 5.993M10 7.5c.333.333.5.667.5 1v2M12.326 4.5v5.996M8.384 4.496c1.674 0 2.116 0 2.116 1.5s-.442 1.5-2.116 1.5M3.205 9.303c-.09.448-.277 1.21-1.241 1.203C1 10.5.5 9.513.5 8V7c0-1.57.5-2.5 1.464-2.494.964.006 1.134.598 1.24 1.342M12.553 10.5h1.953" stroke-width="1.2" stroke="currentColor" fill="none" stroke-linecap="square"></path></svg></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar data-v-e295ff25><!--[--><!--]--><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="KurimulaAiri的小窝"><!--[--><i class="vp-icon fa-solid fa-house" sizing="both"></i><!--]-->KurimulaAiri的小窝<!----></a></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable active"><i class="vp-icon fa-solid fa-book" sizing="both"></i><a class="route-link route-link-active auto-link vp-sidebar-title no-external-link-icon" href="/art/" aria-label="文章"><!---->文章<!----></a><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/art/Memorandum.html" aria-label="备忘录"><!--[--><i class="vp-icon fa-solid fa-clipboard-check" sizing="both"></i><!--]-->备忘录<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><i class="vp-icon fa-solid fa-book-open" sizing="both"></i><span class="vp-sidebar-title">学习</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><i class="vp-icon fa-solid fa-ellipsis" sizing="both"></i><span class="vp-sidebar-title">杂项</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/art/other/C.html" aria-label="C语言的一些知识点"><!--[--><i class="vp-icon fa-solid fa-code" sizing="both"></i><!--]-->C语言的一些知识点<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/art/other/LaTex.html" aria-label="LaTex常用公式标记"><!--[--><i class="vp-icon fa-solid fa-inbox" sizing="both"></i><!--]-->LaTex常用公式标记<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/art/other/secret.html" aria-label="一些神秘的东西"><!--[--><i class="vp-icon fa-solid fa-question" sizing="both"></i><!--]-->一些神秘的东西<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/art/other/jiqixuexibiji.html" aria-label="机器学习复习笔记"><!--[--><i class="vp-icon fa-solid fa-earth-americas" sizing="both"></i><!--]-->机器学习复习笔记<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/art/other/final_jiqixuexi.html" aria-label="机器学习选择题"><!--[--><i class="vp-icon fa-solid fa-earth-americas" sizing="both"></i><!--]-->机器学习选择题<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/art/other/Test.html" aria-label="测试用"><!--[--><i class="vp-icon fa-solid fa-code" sizing="both"></i><!--]-->测试用<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/art/other/final_jiwang.html" aria-label="计网选择题"><!--[--><i class="vp-icon fa-solid fa-earth-americas" sizing="both"></i><!--]-->计网选择题<!----></a></li></ul></section></li></ul></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/intro.html" aria-label="介绍页"><!--[--><i class="vp-icon fa-solid fa-circle-info" sizing="both"></i><!--]-->介绍页<!----></a></li></ul><!--[--><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><VPIcon icon="earth-americas"></VPIcon>机器学习选择题</h1><div class="page-info"><AuthorInfo isoriginal="false" pageview="true" ispure="false"></AuthorInfo><OriginalInfo isoriginal="false" pageview="true" ispure="false"></OriginalInfo><DateInfo isoriginal="false" pageview="true" ispure="false"></DateInfo><PageViewInfo isoriginal="false" pageview="true" ispure="false"></PageViewInfo><ReadingTimeInfo isoriginal="false" pageview="true" ispure="false"></ReadingTimeInfo><CategoryInfo isoriginal="false" pageview="true" ispure="false"></CategoryInfo><TagInfo isoriginal="false" pageview="true" ispure="false"></TagInfo></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><h3 id="期末随堂测试-数科22级" tabindex="-1"><a class="header-anchor" href="#期末随堂测试-数科22级"><span>期末随堂测试-数科22级</span></a></h3><h4 id="_1-判断题-使用k-means算法聚类-算法执行过程中有可能出现空簇。" tabindex="-1"><a class="header-anchor" href="#_1-判断题-使用k-means算法聚类-算法执行过程中有可能出现空簇。"><span>1.(判断题) <p>使用k-means算法聚类，算法执行过程中有可能出现空簇。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_2-判断题-基于密度的聚类方法dbscan无需指定簇的个数。" tabindex="-1"><a class="header-anchor" href="#_2-判断题-基于密度的聚类方法dbscan无需指定簇的个数。"><span>2.(判断题) <p>基于密度的聚类方法DBSCAN无需指定簇的个数。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_3-判断题-使用基于密度的聚类方法dbscan后-每个样本都会归到某个簇中。" tabindex="-1"><a class="header-anchor" href="#_3-判断题-使用基于密度的聚类方法dbscan后-每个样本都会归到某个簇中。"><span>3.(判断题) <p>使用基于密度的聚类方法DBSCAN后，每个样本都会归到某个簇中。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_4-判断题-使用基于凝聚的层次聚类算法agnes聚类后-每个样本都会归到某个簇中。" tabindex="-1"><a class="header-anchor" href="#_4-判断题-使用基于凝聚的层次聚类算法agnes聚类后-每个样本都会归到某个簇中。"><span>4.(判断题) <p><strong>使用基于凝聚的层次聚类算法</strong><strong>AGNES聚类后，每个样本都会归到某个簇中。</strong></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_5-判断题-基于凝聚的层次聚类算法agnes无需指定簇的个数。" tabindex="-1"><a class="header-anchor" href="#_5-判断题-基于凝聚的层次聚类算法agnes无需指定簇的个数。"><span>5.(判断题) <p><strong>基于凝聚的层次聚类算法</strong><strong>AGNES无需指定簇的个数。</strong></p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_6-判断题-聚类评价指标rand-index和adjusted-rand-index均需要带有标注信息的样本。" tabindex="-1"><a class="header-anchor" href="#_6-判断题-聚类评价指标rand-index和adjusted-rand-index均需要带有标注信息的样本。"><span>6.(判断题) <p>聚类评价指标Rand Index和Adjusted Rand Index均需要带有标注信息的样本。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_7-判断题-聚类评价指标轮廓系数silhouette-coefficient需要带有标注信息的样本。" tabindex="-1"><a class="header-anchor" href="#_7-判断题-聚类评价指标轮廓系数silhouette-coefficient需要带有标注信息的样本。"><span>7.(判断题) <p>聚类评价指标轮廓系数silhouette coefficient需要带有标注信息的样本。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_8-判断题-当无法确定簇的个数k时-可以使用轮廓系数silhouette-coefficient或者平方误差来指导选择合适的k。" tabindex="-1"><a class="header-anchor" href="#_8-判断题-当无法确定簇的个数k时-可以使用轮廓系数silhouette-coefficient或者平方误差来指导选择合适的k。"><span>8.(判断题) <p>当无法确定簇的个数k时，可以使用轮廓系数silhouette coefficient或者平方误差来指导选择合适的k。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_9-判断题-基于凝聚的层次聚类算法agnes的结果与簇间距离的计算方式有关系-不同的距离计算方式可能得到不同的结果。" tabindex="-1"><a class="header-anchor" href="#_9-判断题-基于凝聚的层次聚类算法agnes的结果与簇间距离的计算方式有关系-不同的距离计算方式可能得到不同的结果。"><span>9.(判断题) <p><strong>基于凝聚的层次聚类算法</strong><strong>AGNES的结果与簇间距离的计算方式有关系，不同的距离计算方式可能得到不同的结果。</strong></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_10-单选题-下列关于binarizer-copy-说法正确的是" tabindex="-1"><a class="header-anchor" href="#_10-单选题-下列关于binarizer-copy-说法正确的是"><span>10.(单选题) <p>下列关于Binarizer(copy=)说法正确的是</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>copy=True可以保证在使用该类的过程中，输入数据不会被修改。</p></strong></li><li><p>copy=True没有实质性作用，可以忽略。</p></li><li><p>在使用该类时，输入数据总是不会被 修改。</p></li></ul></li></ul><h4 id="_11-单选题-下列选项中属于无监督学习算法的是" tabindex="-1"><a class="header-anchor" href="#_11-单选题-下列选项中属于无监督学习算法的是"><span>11.(单选题) <p>下列选项中属于无监督学习算法的是？</p></span></a></h4><ul><li>选项: <ul><li><p>SVM</p></li><li><p>随机森林</p></li><li id="blue-msg"><strong><p>PCA</p></strong></li><li><p>LDA</p></li></ul></li></ul><h4 id="_12-判断题-k-均值聚类是寻找平方误差最小的簇划分。" tabindex="-1"><a class="header-anchor" href="#_12-判断题-k-均值聚类是寻找平方误差最小的簇划分。"><span>12.(判断题) <p>k-均值聚类是寻找平方误差最小的簇划分。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_13-判断题-k-均值聚类中的k是指特征的维度。" tabindex="-1"><a class="header-anchor" href="#_13-判断题-k-均值聚类中的k是指特征的维度。"><span>13.(判断题) <p>k-均值聚类中的k是指特征的维度。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_14-判断题-k-均值聚类的结果与初始聚类中心的选取无关。" tabindex="-1"><a class="header-anchor" href="#_14-判断题-k-均值聚类的结果与初始聚类中心的选取无关。"><span>14.(判断题) <p>k-均值聚类的结果与初始聚类中心的选取无关。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_15-单选题-下列选项中关于k-means-说法正确的是" tabindex="-1"><a class="header-anchor" href="#_15-单选题-下列选项中关于k-means-说法正确的是"><span>15.(单选题) <p>下列选项中关于k-means++说法正确的是</p></span></a></h4><ul><li>选项: <ul><li><p>k-means++跟k-means一样，都是聚类算法。</p></li><li id="blue-msg"><strong><p>k-means++是一种挑选初始聚类中心的算法。</p></strong></li><li><p>k-means++是k-means的一种改进，可以解决k-means在大数据情况下速度慢的问题。</p></li><li><p>针对相同的数据集，使用k-means++得到的结果总是相同。</p></li></ul></li></ul><h4 id="_16-单选题-在实际使用k-means算法时-往往需要运行多次-然后根据每次的平方误差选取最优的一次。在使用sklearn时-kmeans类的初始化参数中设置该次数的是" tabindex="-1"><a class="header-anchor" href="#_16-单选题-在实际使用k-means算法时-往往需要运行多次-然后根据每次的平方误差选取最优的一次。在使用sklearn时-kmeans类的初始化参数中设置该次数的是"><span>16.(单选题) <p>在实际使用k-means算法时，往往需要运行多次，然后根据每次的平方误差选取最优的一次。在使用sklearn时，KMeans类的初始化参数中设置该次数的是？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p><strong>n_init </strong></p></strong></li><li><p><strong>init</strong></p></li><li><p><strong>n_clusters</strong><strong></strong></p></li><li><p>max_iter</p></li></ul></li></ul><h4 id="_17-单选题-在使用sklearn时-kmeans类哪个成员变量可以返回最终的聚类中心" tabindex="-1"><a class="header-anchor" href="#_17-单选题-在使用sklearn时-kmeans类哪个成员变量可以返回最终的聚类中心"><span>17.(单选题) <p>在使用sklearn时，KMeans类哪个成员变量可以返回最终的聚类中心？</p></span></a></h4><ul><li>选项: <ul><li><p><strong>inertia_ </strong></p></li><li id="blue-msg"><strong><p><strong>cluster_centers</strong><strong>_</strong> </p></strong></li><li><p><strong>labels_ </strong></p></li><li><p><strong>n_iter_</strong></p></li></ul></li></ul><h4 id="_18-判断题-mini-batch-k-means是k-means的一种改进-可以解决k-means在大数据情况下速度慢的问题。" tabindex="-1"><a class="header-anchor" href="#_18-判断题-mini-batch-k-means是k-means的一种改进-可以解决k-means在大数据情况下速度慢的问题。"><span>18.(判断题) <p><strong>mini batch k-means</strong>是k-means的一种改进，可以解决k-means在大数据情况下速度慢的问题。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_19-单选题-mini-batch-k-mean的核心思想是-每次从所有样本中随机选取一批样本来更新聚类中心。请问sklearn-cluster-minibatchkmeans类中哪个参数是设置每批样本的数量" tabindex="-1"><a class="header-anchor" href="#_19-单选题-mini-batch-k-mean的核心思想是-每次从所有样本中随机选取一批样本来更新聚类中心。请问sklearn-cluster-minibatchkmeans类中哪个参数是设置每批样本的数量"><span>19.(单选题) <p>mini batch k-mean的核心思想是：每次从所有样本中随机选取一批样本来更新聚类中心。请问sklearn.cluster.MiniBatchKMeans类中哪个参数是设置每批样本的数量？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p><strong>batch_size</strong></p></strong></li><li><p><strong>n_clusters</strong><strong></strong></p></li><li><p><strong>n_init </strong></p></li><li><p><strong>init</strong><strong></strong></p></li></ul></li></ul><h4 id="_20-单选题-下列关于k-means算法的运行时间叙述正确的是" tabindex="-1"><a class="header-anchor" href="#_20-单选题-下列关于k-means算法的运行时间叙述正确的是"><span>20.(单选题) <p>下列关于k-means算法的运行时间叙述正确的是</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>运行时间与样本数量有关系，样本量越大，时间越长。</p></strong></li><li><p>运行时间受特征维度影响较大，样本数量几乎没有影响</p></li><li><p>运行时间受样本数量影响较大，特征维度几乎没有影响</p></li></ul></li></ul><h4 id="_21-单选题-回归问题和分类问题的区别是" tabindex="-1"><a class="header-anchor" href="#_21-单选题-回归问题和分类问题的区别是"><span>21.(单选题) <p>回归问题和分类问题的区别是？</p></span></a></h4><ul><li>选项: <ul><li><p>特征不同</p></li><li><p>样本数量不同</p></li><li id="blue-msg"><strong><p>标注不同</p></strong></li><li><p>前者是无监督学习任务，后者是监督学习任务。</p></li></ul></li></ul><h4 id="_22-判断题-用于解决回归问题的knn算法和用于解决分类问题的knn算法的核心部分相同-均需找到与测试样本距离最近的k个训练样本。" tabindex="-1"><a class="header-anchor" href="#_22-判断题-用于解决回归问题的knn算法和用于解决分类问题的knn算法的核心部分相同-均需找到与测试样本距离最近的k个训练样本。"><span>22.(判断题) <p>用于解决回归问题的KNN算法和用于解决分类问题的KNN算法的核心部分相同，均需找到与测试样本距离最近的k个训练样本。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_23-判断题-当样本数量较少时-特别是样本量小于或者接近特征的维度-线性回归的最小二乘法不稳定。" tabindex="-1"><a class="header-anchor" href="#_23-判断题-当样本数量较少时-特别是样本量小于或者接近特征的维度-线性回归的最小二乘法不稳定。"><span>23.(判断题) <p>当样本数量较少时，特别是样本量小于或者接近特征的维度，线性回归的最小二乘法不稳定。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_24-判断题-构建回归树需要考虑如何选择切分变量和切分点。" tabindex="-1"><a class="header-anchor" href="#_24-判断题-构建回归树需要考虑如何选择切分变量和切分点。"><span>24.(判断题) <p>构建回归树需要考虑如何选择切分变量和切分点。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_25-判断题-在涉及目标值标准化的问题中-在计算mse和mae时需要将回归模型的输出做反变换。" tabindex="-1"><a class="header-anchor" href="#_25-判断题-在涉及目标值标准化的问题中-在计算mse和mae时需要将回归模型的输出做反变换。"><span>25.(判断题) <p>在涉及目标值标准化的问题中，在计算MSE和MAE时需要将回归模型的输出做反变换。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_26-判断题-回归问题的提升树算法-通过不断拟合已有模型的误差来学习弱学习器-最终得到强学习器。" tabindex="-1"><a class="header-anchor" href="#_26-判断题-回归问题的提升树算法-通过不断拟合已有模型的误差来学习弱学习器-最终得到强学习器。"><span>26.(判断题) <p>回归问题的提升树算法，通过不断拟合已有模型的误差来学习弱学习器，最终得到强学习器。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_27-判断题-通常把反映数据内在规律的信息叫做特征。" tabindex="-1"><a class="header-anchor" href="#_27-判断题-通常把反映数据内在规律的信息叫做特征。"><span>27.(判断题) <p>通常把反映数据内在规律的信息叫做特征。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_28-多选题-机器学习三要素是" tabindex="-1"><a class="header-anchor" href="#_28-多选题-机器学习三要素是"><span>28.(多选题) <p>机器学习三要素是？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>模型</p></strong></li><li id="blue-msg"><strong><p>策略</p></strong></li><li id="blue-msg"><strong><p>算法</p></strong></li><li><p>数据</p></li></ul></li></ul><h4 id="_29-多选题-用于评价分类模型性能的指标通常有" tabindex="-1"><a class="header-anchor" href="#_29-多选题-用于评价分类模型性能的指标通常有"><span>29.(多选题) <p>用于评价分类模型性能的指标通常有</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>准确率</p></strong></li><li id="blue-msg"><strong><p>精确率</p></strong></li><li id="blue-msg"><strong><p>召回率</p></strong></li><li id="blue-msg"><strong><p>F1-值</p></strong></li><li><p>事件发生的几率</p></li></ul></li></ul><h4 id="_30-单选题-在哪一种距离下-单位圆周是顶点在坐标轴上的正方形" tabindex="-1"><a class="header-anchor" href="#_30-单选题-在哪一种距离下-单位圆周是顶点在坐标轴上的正方形"><span>30.(单选题) <p>在哪一种距离下，单位圆周是顶点在坐标轴上的正方形？</p></span></a></h4><ul><li>选项: <ul><li><p>欧式距离</p></li><li id="blue-msg"><strong><p>曼哈顿距离</p></strong></li><li><p>切比雪夫距离</p></li><li><p>p为任意取值的闵可夫斯基距离</p></li></ul></li></ul><h4 id="_31-判断题-回归是无监督学习。" tabindex="-1"><a class="header-anchor" href="#_31-判断题-回归是无监督学习。"><span>31.(判断题) <p>回归是无监督学习。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_32-判断题-回归与分类的区别是-回归模型输出为连续值-分类模型输出为离散值。" tabindex="-1"><a class="header-anchor" href="#_32-判断题-回归与分类的区别是-回归模型输出为连续值-分类模型输出为离散值。"><span>32.(判断题) <p>回归与分类的区别是：回归模型输出为连续值，分类模型输出为离散值。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_33-单选题-最小二乘回归使用什么损失" tabindex="-1"><a class="header-anchor" href="#_33-单选题-最小二乘回归使用什么损失"><span>33.(单选题) <p>最小二乘回归使用什么损失？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>平方损失</p></strong></li><li><p>合页损失</p></li><li><p>对数损失</p></li><li><p>指数损失</p></li></ul></li></ul><h4 id="_34-单选题-岭回归和lasso的正则项分别是" tabindex="-1"><a class="header-anchor" href="#_34-单选题-岭回归和lasso的正则项分别是"><span>34.(单选题) <p>岭回归和Lasso的正则项分别是？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>L2范数和L1范数</p></strong></li><li><p>L1范数和L2范数</p></li><li><p>L0范数和L1范数</p></li><li><p>L2范数和L0范数</p></li></ul></li></ul><h4 id="_35-单选题-下列哪个算法可以抑制离群点的影响" tabindex="-1"><a class="header-anchor" href="#_35-单选题-下列哪个算法可以抑制离群点的影响"><span>35.(单选题) <p>下列哪个算法可以抑制离群点的影响？</p></span></a></h4><ul><li>选项: <ul><li><p>最小乘回归</p></li><li><p>岭回归</p></li><li><p>Lasso回归</p></li><li id="blue-msg"><strong><p>Huber回归</p></strong></li></ul></li></ul><h4 id="_36-多选题-下列指标用于评价回归模型的有" tabindex="-1"><a class="header-anchor" href="#_36-多选题-下列指标用于评价回归模型的有"><span>36.(多选题) <p>下列指标用于评价回归模型的有</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>均方误差</p></strong></li><li id="blue-msg"><strong><p>平均绝对误差</p></strong></li><li id="blue-msg"><strong><p>决定系数</p></strong></li><li><p>召回率</p></li><li><p>F1值</p></li></ul></li></ul><h4 id="_37-判断题-利用knn算法回归时-选取距离测试样本最小的k个训练样本-然后对这k个近邻目标的值进行平均-得到测试样本的预测值。" tabindex="-1"><a class="header-anchor" href="#_37-判断题-利用knn算法回归时-选取距离测试样本最小的k个训练样本-然后对这k个近邻目标的值进行平均-得到测试样本的预测值。"><span>37.(判断题) <p>利用KNN算法回归时，选取距离测试样本最小的K个训练样本，然后对这K个近邻目标的值进行平均，得到测试样本的预测值。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_38-判断题-在构建回归树时-关键问题是如何选择切分变量和切分点。确定最优切分变量和最优切分点通常使用启发式方法-即先固定切分方向j-确定切分点s-然后" tabindex="-1"><a class="header-anchor" href="#_38-判断题-在构建回归树时-关键问题是如何选择切分变量和切分点。确定最优切分变量和最优切分点通常使用启发式方法-即先固定切分方向j-确定切分点s-然后"><span>38.(判断题) <p>在构建回归树时，关键问题是如何选择切分变量和切分点。确定最优切分变量和最优切分点通常使用启发式方法，即先固定切分方向<em>j</em>，确定切分点<em>s；</em>然后</p></span></a></h4><p>遍历所有<em>j</em>，确定最优切分变量和切分点(<em>j</em>,<em>s</em>)。</p><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_39-判断题-针对回归问题-在构建提升树时-每次迭代是针对残差进行拟合来构建回归树的。" tabindex="-1"><a class="header-anchor" href="#_39-判断题-针对回归问题-在构建提升树时-每次迭代是针对残差进行拟合来构建回归树的。"><span>39.(判断题) <p>针对回归问题，在构建提升树时，每次迭代是针对残差进行拟合来构建回归树的。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_40-单选题-支持向量回归的损失函数是" tabindex="-1"><a class="header-anchor" href="#_40-单选题-支持向量回归的损失函数是"><span>40.(单选题) <p>支持向量回归的损失函数是？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p><strong>epsilon_insensitive</strong></p></strong></li><li><p>平方损失</p></li><li><p>Huber损失</p></li><li><p>指数损失</p></li></ul></li></ul><h4 id="_41-判断题-使用pca降维是无损的。" tabindex="-1"><a class="header-anchor" href="#_41-判断题-使用pca降维是无损的。"><span>41.(判断题) <p>使用PCA降维是无损的。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_42-判断题-pca降维是无监督学习方法。" tabindex="-1"><a class="header-anchor" href="#_42-判断题-pca降维是无监督学习方法。"><span>42.(判断题) <p>PCA降维是无监督学习方法。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_43-判断题-pca的核心思想是投影到方差更大的方向。" tabindex="-1"><a class="header-anchor" href="#_43-判断题-pca的核心思想是投影到方差更大的方向。"><span>43.(判断题) <p>PCA的核心思想是投影到方差更大的方向。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_44-判断题-pca需要先对样本进行中心化处理-即每个样本减去样本均值。" tabindex="-1"><a class="header-anchor" href="#_44-判断题-pca需要先对样本进行中心化处理-即每个样本减去样本均值。"><span>44.(判断题) <p>PCA需要先对样本进行中心化处理，即每个样本减去样本均值。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_45-多选题-在pca降维时-关于目标维度和累积贡献率的关系-下述说法正确的是" tabindex="-1"><a class="header-anchor" href="#_45-多选题-在pca降维时-关于目标维度和累积贡献率的关系-下述说法正确的是"><span>45.(多选题) <p>在PCA降维时，关于目标维度和累积贡献率的关系，下述说法正确的是</p></span></a></h4><ul><li>选项: <ul><li><p>目标维度越大，累积贡献率越小</p></li><li id="blue-msg"><strong><p>目标维度越大，累积贡献率越大</p></strong></li><li><p>累积贡献率和目标维度无关</p></li><li id="blue-msg"><strong><p>当目标维度和特征维度相同时，累积贡献率等于1.</p></strong></li></ul></li></ul><h4 id="_46-判断题-累积贡献率的取值范围是-大于0小于1" tabindex="-1"><a class="header-anchor" href="#_46-判断题-累积贡献率的取值范围是-大于0小于1"><span>46.(判断题) <p>累积贡献率的取值范围是：大于0小于1</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_47-多选题-关于sklearn-decomposition-pca-n-components-中的参数n-components-叙述正确的有" tabindex="-1"><a class="header-anchor" href="#_47-多选题-关于sklearn-decomposition-pca-n-components-中的参数n-components-叙述正确的有"><span>47.(多选题) <p>关于sklearn.decomposition.<strong>PCA</strong>(<strong>n_components)中的参数n_components，叙述正确的有</strong></p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p><strong>n_components可以取大于等于1的整数，此时表示目标维度</strong></p></strong></li><li id="blue-msg"><strong><p><strong>n_components</strong>取值为(0，1]之间的浮点数时，用累积贡献率来决定维数，即目标维度要使的对应的累积贡献率刚好大于等于该值</p></strong></li><li id="blue-msg"><strong><p>默认时无输入，此时n_components=min(样本数，特征数)</p></strong></li><li id="blue-msg"><strong><p>取值为字符串“mle”时, 用MLE算法自己选择一定数量的主成分特征来降维</p></strong></li></ul></li></ul><h4 id="_48-判断题-可以通过sklearn-decomposition-pca-中的成员变量explained-variance-获取协方差矩阵的特征根。" tabindex="-1"><a class="header-anchor" href="#_48-判断题-可以通过sklearn-decomposition-pca-中的成员变量explained-variance-获取协方差矩阵的特征根。"><span>48.(判断题) <p><strong>可以通过sklearn.decomposition.PCA()中的成员变量explained_variance</strong><strong>_，获取协方差矩阵的特征根。</strong></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_49-判断题-可以对sklearn-decomposition-pca-中的成员变量explained-variance-ratio-进行求和-来获取累积贡献率。" tabindex="-1"><a class="header-anchor" href="#_49-判断题-可以对sklearn-decomposition-pca-中的成员变量explained-variance-ratio-进行求和-来获取累积贡献率。"><span>49.(判断题) <p><strong>可以对sklearn.decomposition.PCA()中的成员变量explained_variance_ratio_进行求和</strong><strong>，来获取累积贡献率。</strong></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_50-判断题-可以通过sklearn-decomposition-pca-中的成员变量mean-获取训练样本的均值。" tabindex="-1"><a class="header-anchor" href="#_50-判断题-可以通过sklearn-decomposition-pca-中的成员变量mean-获取训练样本的均值。"><span>50.(判断题) <p> <strong>可以通过sklearn.decomposition.PCA()中的成员变量mean_</strong><strong>，获取训练样本的均值。</strong></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_51-判断题-可以通过sklearn-decomposition-pca-中的成员变量components-获取降维矩阵。" tabindex="-1"><a class="header-anchor" href="#_51-判断题-可以通过sklearn-decomposition-pca-中的成员变量components-获取降维矩阵。"><span>51.(判断题) <p><strong>可以通过sklearn.decomposition.PCA()中的成员变量components_ ，获取降维矩阵。</strong></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_52-判断题-kernelpca是在更高维空间进行降维-所以需要设计低维到高位的投影函数。" tabindex="-1"><a class="header-anchor" href="#_52-判断题-kernelpca是在更高维空间进行降维-所以需要设计低维到高位的投影函数。"><span>52.(判断题) <p>KernelPCA是在更高维空间进行降维，所以需要设计低维到高位的投影函数。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_53-单选题-sklearn中使用核pca的类是" tabindex="-1"><a class="header-anchor" href="#_53-单选题-sklearn中使用核pca的类是"><span>53.(单选题) <p>sklearn中使用核PCA的类是：</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>KernelPCA</p></strong></li><li><p>PCA</p></li><li><p><strong>LinearDiscriminantAnalysis</strong></p></li><li><p>KernelSVM</p></li></ul></li></ul><h4 id="_54-单选题-在sklearn中使用pca和核pca这两个类时-初始化类时-目标维度均使用如下哪个参数指定" tabindex="-1"><a class="header-anchor" href="#_54-单选题-在sklearn中使用pca和核pca这两个类时-初始化类时-目标维度均使用如下哪个参数指定"><span>54.(单选题) <p>在sklearn中使用PCA和核PCA这两个类时，初始化类时，目标维度均使用如下哪个参数指定？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p><strong>n_components</strong></p></strong></li><li><p><strong>kernel</strong></p></li><li><p><strong>gamma</strong></p></li><li><p><strong>degree</strong></p></li></ul></li></ul><h4 id="_55-多选题-在sklearn中-当使用pca类时-如下选项哪些是关于核函数的参数" tabindex="-1"><a class="header-anchor" href="#_55-多选题-在sklearn中-当使用pca类时-如下选项哪些是关于核函数的参数"><span>55.(多选题) <p>在sklearn中，当使用PCA类时，如下选项哪些是关于核函数的参数？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>linear</p></strong></li><li id="blue-msg"><strong><p>poly</p></strong></li><li id="blue-msg"><strong><p>rbf</p></strong></li><li id="blue-msg"><strong><p>sigmoid</p></strong></li></ul></li></ul><h4 id="_56-单选题-在sklearn中-核pca类使用如下哪个参数kernel指定和函数类型" tabindex="-1"><a class="header-anchor" href="#_56-单选题-在sklearn中-核pca类使用如下哪个参数kernel指定和函数类型"><span>56.(单选题) <p><strong>在sklearn中，核PCA类使用如下哪个参数kernel指定和函数类型？</strong></p></span></a></h4><ul><li>选项: <ul><li><p><strong>n_components</strong></p></li><li id="blue-msg"><strong><p><strong>kernel</strong></p></strong></li><li><p><strong>gamma</strong></p></li><li><p><strong>degree</strong></p></li></ul></li></ul><h4 id="_57-判断题-使用核pca时-针对训练集的核矩阵是对称矩阵。" tabindex="-1"><a class="header-anchor" href="#_57-判断题-使用核pca时-针对训练集的核矩阵是对称矩阵。"><span>57.(判断题) <p>使用核PCA时，针对训练集的核矩阵是对称矩阵。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_58-多选题-在核pca的过程中-在训练阶段针对训练集需要完成的步骤有哪些" tabindex="-1"><a class="header-anchor" href="#_58-多选题-在核pca的过程中-在训练阶段针对训练集需要完成的步骤有哪些"><span>58.(多选题) <p>在核PCA的过程中，在训练阶段针对训练集需要完成的步骤有哪些？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>计算核矩阵</p></strong></li><li id="blue-msg"><strong><p>对核矩阵进行中心化处理</p></strong></li><li id="blue-msg"><strong><p>特征值分解，确定投影矩阵</p></strong></li><li><p>通过高维映射确定样本在高维空间中的投影</p></li></ul></li></ul><h4 id="_59-多选题-在核pca的过程中-在测试阶段针对测试集需要完成的步骤有哪些" tabindex="-1"><a class="header-anchor" href="#_59-多选题-在核pca的过程中-在测试阶段针对测试集需要完成的步骤有哪些"><span>59.(多选题) <p>在核PCA的过程中，在测试阶段针对测试集需要完成的步骤有哪些？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>计算测试集对应的核矩阵</p></strong></li><li id="blue-msg"><strong><p>测试集核矩阵中心和</p></strong></li><li id="blue-msg"><strong><p>使用训练阶段确定的投影矩阵，对测试机核矩阵进行投影</p></strong></li><li><p>将结果投影到原始的特征空间</p></li></ul></li></ul><h4 id="_60-判断题-kernelpca是在更高维空间进行降维-所以需要设计低维到高位的投影函数。" tabindex="-1"><a class="header-anchor" href="#_60-判断题-kernelpca是在更高维空间进行降维-所以需要设计低维到高位的投影函数。"><span>60.(判断题) <p>KernelPCA是在更高维空间进行降维，所以需要设计低维到高位的投影函数。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_61-单选题-sklearn中使用核pca的类是" tabindex="-1"><a class="header-anchor" href="#_61-单选题-sklearn中使用核pca的类是"><span>61.(单选题) <p>sklearn中使用核PCA的类是：</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>KernelPCA</p></strong></li><li><p>PCA</p></li><li><p><strong>LinearDiscriminantAnalysis</strong></p></li><li><p>KernelSVM</p></li></ul></li></ul><h4 id="_62-单选题-在sklearn中使用pca和核pca这两个类时-初始化类时-目标维度均使用如下哪个参数指定" tabindex="-1"><a class="header-anchor" href="#_62-单选题-在sklearn中使用pca和核pca这两个类时-初始化类时-目标维度均使用如下哪个参数指定"><span>62.(单选题) <p>在sklearn中使用PCA和核PCA这两个类时，初始化类时，目标维度均使用如下哪个参数指定？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p><strong>n_components</strong></p></strong></li><li><p><strong>kernel</strong></p></li><li><p><strong>gamma</strong></p></li><li><p><strong>degree</strong></p></li></ul></li></ul><h4 id="_63-多选题-在sklearn中-如下选项哪些是关于核pca方法的关于核函数的参数" tabindex="-1"><a class="header-anchor" href="#_63-多选题-在sklearn中-如下选项哪些是关于核pca方法的关于核函数的参数"><span>63.(多选题) <p>在sklearn中，如下选项哪些是关于核PCA方法的关于核函数的参数？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>linear</p></strong></li><li id="blue-msg"><strong><p>poly</p></strong></li><li id="blue-msg"><strong><p>rbf</p></strong></li><li id="blue-msg"><strong><p>sigmoid</p></strong></li></ul></li></ul><h4 id="_64-单选题-在sklearn中-核pca类使用如下哪个参数kernel指定和函数类型" tabindex="-1"><a class="header-anchor" href="#_64-单选题-在sklearn中-核pca类使用如下哪个参数kernel指定和函数类型"><span>64.(单选题) <p><strong>在sklearn中，核PCA类使用如下哪个参数kernel指定和函数类型？</strong></p></span></a></h4><ul><li>选项: <ul><li><p><strong>n_components</strong></p></li><li id="blue-msg"><strong><p><strong>kernel</strong></p></strong></li><li><p><strong>gamma</strong></p></li><li><p><strong>degree</strong></p></li></ul></li></ul><h4 id="_65-判断题-使用核pca时-针对训练集的核矩阵是对称矩阵。" tabindex="-1"><a class="header-anchor" href="#_65-判断题-使用核pca时-针对训练集的核矩阵是对称矩阵。"><span>65.(判断题) <p>使用核PCA时，针对训练集的核矩阵是对称矩阵。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_66-多选题-在核pca的过程中-在训练阶段针对训练集需要完成的步骤有哪些" tabindex="-1"><a class="header-anchor" href="#_66-多选题-在核pca的过程中-在训练阶段针对训练集需要完成的步骤有哪些"><span>66.(多选题) <p>在核PCA的过程中，在训练阶段针对训练集需要完成的步骤有哪些？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>计算核矩阵</p></strong></li><li id="blue-msg"><strong><p>对核矩阵进行中心化处理</p></strong></li><li id="blue-msg"><strong><p>特征值分解，确定投影矩阵</p></strong></li><li><p>通过高维映射确定样本在高维空间中的投影</p></li></ul></li></ul><h4 id="_67-多选题-在核pca的过程中-在测试阶段针对测试集需要完成的步骤有哪些" tabindex="-1"><a class="header-anchor" href="#_67-多选题-在核pca的过程中-在测试阶段针对测试集需要完成的步骤有哪些"><span>67.(多选题) <p>在核PCA的过程中，在测试阶段针对测试集需要完成的步骤有哪些？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>计算测试集对应的核矩阵</p></strong></li><li id="blue-msg"><strong><p>测试集核矩阵中心和</p></strong></li><li id="blue-msg"><strong><p>使用训练阶段确定的投影矩阵，对测试机核矩阵进行投影</p></strong></li><li><p>将结果投影到原始的特征空间</p></li></ul></li></ul><h4 id="_68-多选题-下述降维方法是无监督的有" tabindex="-1"><a class="header-anchor" href="#_68-多选题-下述降维方法是无监督的有"><span>68.(多选题) <p>下述降维方法是无监督的有？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>PCA</p></strong></li><li id="blue-msg"><strong><p>KernelPCA</p></strong></li><li><p>LDA</p></li></ul></li></ul><h4 id="_69-判断题-lda的核心思想是投影后保证类间距离最大化-类内距离最小化。" tabindex="-1"><a class="header-anchor" href="#_69-判断题-lda的核心思想是投影后保证类间距离最大化-类内距离最小化。"><span>69.(判断题) <p>LDA的核心思想是投影后保证类间距离最大化，类内距离最小化。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_70-判断题-pca选择分类性能最好的投影方向。" tabindex="-1"><a class="header-anchor" href="#_70-判断题-pca选择分类性能最好的投影方向。"><span>70.(判断题) <p>PCA选择分类性能最好的投影方向。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_71-单选题-lda降维后的维度需要满足" tabindex="-1"><a class="header-anchor" href="#_71-单选题-lda降维后的维度需要满足"><span>71.(单选题) <p>LDA降维后的维度需要满足？</p></span></a></h4><ul><li>选项: <ul><li><p>小于样本个数即可</p></li><li><p>小于类别数即可</p></li><li><p>可以等于样本个数，也可以等于类别数</p></li><li id="blue-msg"><strong><p>不超过样本个数，同时小于类别数</p></strong></li></ul></li></ul><h4 id="_72-判断题-lda无需对样本中心化处理。" tabindex="-1"><a class="header-anchor" href="#_72-判断题-lda无需对样本中心化处理。"><span>72.(判断题) <p>LDA无需对样本中心化处理。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_73-单选题-用于lda降维的类sklearn-discriminant-analysis-lineardiscriminantanalysis-其哪个参数用于指定目标维度" tabindex="-1"><a class="header-anchor" href="#_73-单选题-用于lda降维的类sklearn-discriminant-analysis-lineardiscriminantanalysis-其哪个参数用于指定目标维度"><span>73.(单选题) <p>用于LDA降维的类sklearn.discriminant_analysis.LinearDiscriminantAnalysis，其哪个参数用于指定目标维度？</p></span></a></h4><ul><li>选项: <ul><li><p><strong style="box-sizing:border-box;color:#212529;font-family:-apple-system,BlinkMacSystemFont,&amp;quot;font-size:16px;font-style:normal;font-variant:normal;font-weight:bold;letter-spacing:normal;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;" data-mce-fragment="1">solver</strong></p></li><li id="blue-msg"><strong><p><span style="display:inline !important;float:none;background-color:#ffffff;color:#212529;font-family:-apple-system,BlinkMacSystemFont,&#39;Segoe UI&#39;,Roboto,&#39;Helvetica Neue&#39;,Arial,&#39;Noto Sans&#39;,sans-serif,&#39;Apple Color Emoji&#39;,&#39;Segoe UI Emoji&#39;,&#39;Segoe UI Symbol&#39;,&#39;Noto Color Emoji&#39;;font-size:16px;font-style:normal;font-variant:normal;font-weight:bold;letter-spacing:normal;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;">n_components</span></p></strong></li><li><p><strong style="box-sizing:border-box;color:#212529;font-family:-apple-system,BlinkMacSystemFont,&amp;quot;font-size:16px;font-style:normal;font-variant:normal;font-weight:bold;letter-spacing:normal;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;" data-mce-fragment="1">covariance_estimator</strong></p></li><li><p><em><span style="display:inline !important;float:none;background-color:#ffffff;color:#212529;font-family:-apple-system,BlinkMacSystemFont,&#39;Segoe UI&#39;,Roboto,&#39;Helvetica Neue&#39;,Arial,&#39;Noto Sans&#39;,sans-serif,&#39;Apple Color Emoji&#39;,&#39;Segoe UI Emoji&#39;,&#39;Segoe UI Symbol&#39;,&#39;Noto Color Emoji&#39;;font-size:16px;font-style:normal;font-variant:normal;font-weight:bold;letter-spacing:normal;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;">store_covariance</span></em></p></li></ul></li></ul><h4 id="_74-单选题-用于lda降维的类sklearn-discriminant-analysis-lineardiscriminantanalysis-其哪个方法用于测试样本的投影" tabindex="-1"><a class="header-anchor" href="#_74-单选题-用于lda降维的类sklearn-discriminant-analysis-lineardiscriminantanalysis-其哪个方法用于测试样本的投影"><span>74.(单选题) <p>用于LDA降维的类sklearn.discriminant_analysis.LinearDiscriminantAnalysis，其哪个方法用于测试样本的投影？</p></span></a></h4><ul><li>选项: <ul><li><p><a class="reference internal" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit_transform" href="https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code></a></p></li><li><p>fit</p></li><li id="blue-msg"><strong><p>transform</p></strong></li><li><p>predict</p></li></ul></li></ul><h4 id="_75-单选题-用于lda降维的类sklearn-discriminant-analysis-lineardiscriminantanalysis-其哪个方法用于预测类别" tabindex="-1"><a class="header-anchor" href="#_75-单选题-用于lda降维的类sklearn-discriminant-analysis-lineardiscriminantanalysis-其哪个方法用于预测类别"><span>75.(单选题) <p>用于LDA降维的类sklearn.discriminant_analysis.LinearDiscriminantAnalysis，其哪个方法用于预测类别？</p></span></a></h4><ul><li>选项: <ul><li><p>fit_transform</p></li><li><p>fit</p></li><li><p>transform</p></li><li id="blue-msg"><strong><p>predict</p></strong></li></ul></li></ul><h4 id="_76-单选题-l1正则化和l2正则化中-哪一个更有让所学参数具有稀疏的趋势" tabindex="-1"><a class="header-anchor" href="#_76-单选题-l1正则化和l2正则化中-哪一个更有让所学参数具有稀疏的趋势"><span>76.(单选题) <p>L1正则化和L2正则化中，哪一个更有让所学参数具有稀疏的趋势？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>L1正则化</p></strong></li><li><p>L2正则化</p></li><li><p>它们没有区别</p></li></ul></li></ul><h4 id="_77-判断题-在回归问题中-对标注-即输出值-做标准化-不影响回归模型的评价指标值。" tabindex="-1"><a class="header-anchor" href="#_77-判断题-在回归问题中-对标注-即输出值-做标准化-不影响回归模型的评价指标值。"><span>77.(判断题) <p>在回归问题中，对标注（即输出值）做标准化，不影响回归模型的评价指标值。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_78-多选题-在回归问题中-对标注-即输出值-做标准化-回归模型的评价指标值改变的是" tabindex="-1"><a class="header-anchor" href="#_78-多选题-在回归问题中-对标注-即输出值-做标准化-回归模型的评价指标值改变的是"><span>78.(多选题) <p>在回归问题中，对标注（即输出值）做标准化，回归模型的评价指标值改变的是？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p><strong>均方误差</strong></p></strong></li><li id="blue-msg"><strong><p><strong>平均绝对误差</strong></p></strong></li><li><p><strong>决定系数</strong></p></li><li><p>召回率</p></li></ul></li></ul><h4 id="_79-判断题-在前馈神经网络中-如果每一层均不使用非线性激活函数-那么该神经网络是一个线性模型。" tabindex="-1"><a class="header-anchor" href="#_79-判断题-在前馈神经网络中-如果每一层均不使用非线性激活函数-那么该神经网络是一个线性模型。"><span>79.(判断题) <p>在前馈神经网络中，如果每一层均不使用非线性激活函数，那么该神经网络是一个线性模型。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_80-判断题-使用前馈神经网络进行推理-是正向传播过程。" tabindex="-1"><a class="header-anchor" href="#_80-判断题-使用前馈神经网络进行推理-是正向传播过程。"><span>80.(判断题) <p>使用前馈神经网络进行推理，是正向传播过程。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_81-判断题-训练前馈神经网络的核心过程是误差反向传播过程。" tabindex="-1"><a class="header-anchor" href="#_81-判断题-训练前馈神经网络的核心过程是误差反向传播过程。"><span>81.(判断题) <p>训练前馈神经网络的核心过程是误差反向传播过程。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_82-单选题-使用如下网络-输入是-1-1-的-输出是多少" tabindex="-1"><a class="header-anchor" href="#_82-单选题-使用如下网络-输入是-1-1-的-输出是多少"><span>82.(单选题) <p>使用如下网络，输入是（1,1）的，输出是多少？</p></span></a></h4><p>其中，激活函数是变异的符号函数，即如果输入是非负数，那么输出为1；否则输出0.</p><p><img src="//img.ketangpai.com/ketangpai.aliapp.com/1/webroot/Uploads/Download/2025-05-16/68267a587c5c1.png?OSSAccessKeyId=LTAItfPkNIKJFibY&amp;Expires=4900952152&amp;Signature=MwaOrMKTYv52SaIowxgczpQK1TY%3D" width="428" height="178" crossOrigin="anonymous"></p><ul><li>选项: <ul><li id="blue-msg"><strong><p>0</p></strong></li><li><p>1</p></li><li><p>-0.5</p></li><li><p>-1.5</p></li></ul></li></ul><h4 id="_83-多选题-在推理阶段-对于给定的输入-一个前馈神经网络的输出结果和以下哪些项有关" tabindex="-1"><a class="header-anchor" href="#_83-多选题-在推理阶段-对于给定的输入-一个前馈神经网络的输出结果和以下哪些项有关"><span>83.(多选题) <p>在推理阶段，对于给定的输入，一个前馈神经网络的输出结果和以下哪些项有关？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>激活函数</p></strong></li><li id="blue-msg"><strong><p>相邻两层之间的权重系数</p></strong></li><li id="blue-msg"><strong><p>每个神经元的偏置</p></strong></li><li><p>学习率</p></li></ul></li></ul><h4 id="_84-多选题-在训练阶段-对于给定的网络结构-最终的模型和以下哪些项有关" tabindex="-1"><a class="header-anchor" href="#_84-多选题-在训练阶段-对于给定的网络结构-最终的模型和以下哪些项有关"><span>84.(多选题) <p>在训练阶段，对于给定的网络结构，最终的模型和以下哪些项有关？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>学习率</p></strong></li><li id="blue-msg"><strong><p>训练轮数（Epoch）</p></strong></li><li id="blue-msg"><strong><p>参数初始化方法</p></strong></li><li id="blue-msg"><strong><p>损失函数</p></strong></li></ul></li></ul><h4 id="_85-判断题-在使用sklearn的数据标准化类的时候-成员函数fit-transform和transform是一样的-没有区别。" tabindex="-1"><a class="header-anchor" href="#_85-判断题-在使用sklearn的数据标准化类的时候-成员函数fit-transform和transform是一样的-没有区别。"><span>85.(判断题) <p>在使用sklearn的数据标准化类的时候，成员函数fit_transform和transform是一样的，没有区别。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_86-判断题-binarizer类中的fit-方法没有实质性作用。" tabindex="-1"><a class="header-anchor" href="#_86-判断题-binarizer类中的fit-方法没有实质性作用。"><span>86.(判断题) <p>Binarizer类中的fit()方法没有实质性作用。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_87-判断题-在测试集上可以使用maxabsscale类的fit-transform-方法。" tabindex="-1"><a class="header-anchor" href="#_87-判断题-在测试集上可以使用maxabsscale类的fit-transform-方法。"><span>87.(判断题) <p>在测试集上可以使用MaxAbsScale类的fit_transform()方法。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_88-判断题-normalizer类当norm-inf-时-实现的功能与maxabsscale类一样。" tabindex="-1"><a class="header-anchor" href="#_88-判断题-normalizer类当norm-inf-时-实现的功能与maxabsscale类一样。"><span>88.(判断题) <p>Normalizer类当norm=&#39;inf&#39;时，实现的功能与MaxAbsScale类一样。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_89-单选题-在定义卷积层是-卷积核的通道数如何确定" tabindex="-1"><a class="header-anchor" href="#_89-单选题-在定义卷积层是-卷积核的通道数如何确定"><span>89.(单选题) <p>在定义卷积层是，卷积核的通道数如何确定？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>必须等于当前被卷积的数据的通道数</p></strong></li><li><p>由人工确定</p></li><li><p>等于3</p></li><li><p>等于输出数据的通道数</p></li></ul></li></ul><h4 id="_90-判断题-使用standardscaler变换以后-数据的取值范围变为-0-1-。" tabindex="-1"><a class="header-anchor" href="#_90-判断题-使用standardscaler变换以后-数据的取值范围变为-0-1-。"><span>90.(判断题) <p>使用StandardScaler变换以后，数据的取值范围变为(0,1)。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_91-单选题-卷积结果的通道数如何确定" tabindex="-1"><a class="header-anchor" href="#_91-单选题-卷积结果的通道数如何确定"><span>91.(单选题) <p>卷积结果的通道数如何确定？</p></span></a></h4><ul><li>选项: <ul><li><p>等于卷积核的通道数</p></li><li id="blue-msg"><strong><p>等于卷积核的数量</p></strong></li><li><p>等于当前被卷积的数据的通道数</p></li><li><p>等于3</p></li></ul></li></ul><h4 id="_92-单选题-针对输入是224x224x3的特征-使用11x11x3的卷积核-步长为4-填充为2-那么输出特征的空间尺寸为" tabindex="-1"><a class="header-anchor" href="#_92-单选题-针对输入是224x224x3的特征-使用11x11x3的卷积核-步长为4-填充为2-那么输出特征的空间尺寸为"><span>92.(单选题) <p>针对输入是224X224X3的特征，使用11X11X3的卷积核，步长为4，填充为2，那么输出特征的空间尺寸为？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>55X55</p></strong></li><li><p>224X224</p></li><li><p>112X112</p></li><li><p>234X234</p></li></ul></li></ul><h4 id="_93-单选题-连续使用三次3x3卷积-其感受野相当于多大" tabindex="-1"><a class="header-anchor" href="#_93-单选题-连续使用三次3x3卷积-其感受野相当于多大"><span>93.(单选题) <p>连续使用三次3X3卷积，其感受野相当于多大？</p></span></a></h4><ul><li>选项: <ul><li><p>3X3</p></li><li><p>5X5</p></li><li id="blue-msg"><strong><p>7X7</p></strong></li><li><p>9X9</p></li></ul></li></ul><h4 id="_94-判断题-vgg的特点是连续使用堆叠的3x3卷积核来扩大感受野。" tabindex="-1"><a class="header-anchor" href="#_94-判断题-vgg的特点是连续使用堆叠的3x3卷积核来扩大感受野。"><span>94.(判断题) <p>VGG的特点是连续使用堆叠的3X3卷积核来扩大感受野。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_95-判断题-1x1卷积核的作用相当于对特征在通道方向上加权求和。" tabindex="-1"><a class="header-anchor" href="#_95-判断题-1x1卷积核的作用相当于对特征在通道方向上加权求和。"><span>95.(判断题) <p>1X1卷积核的作用相当于对特征在通道方向上加权求和。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_96-判断题-resnet使用残差连接大大加深了卷积神经网络的深度。" tabindex="-1"><a class="header-anchor" href="#_96-判断题-resnet使用残差连接大大加深了卷积神经网络的深度。"><span>96.(判断题) <p>ResNet使用残差连接大大加深了卷积神经网络的深度。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_97-判断题-densenet通过特征重用-既大幅度减少了网络的参数量-又在一定程度上缓解了梯度消失问题的产生。" tabindex="-1"><a class="header-anchor" href="#_97-判断题-densenet通过特征重用-既大幅度减少了网络的参数量-又在一定程度上缓解了梯度消失问题的产生。"><span>97.(判断题) <p>DenseNet通过特征重用，既大幅度减少了网络的参数量，又在一定程度上缓解了梯度消失问题的产生。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h3 id="期末上机测试-数科22" tabindex="-1"><a class="header-anchor" href="#期末上机测试-数科22"><span>期末上机测试-数科22</span></a></h3><h4 id="_1-填空题-原始数据的样本数量为" tabindex="-1"><a class="header-anchor" href="#_1-填空题-原始数据的样本数量为"><span>1.(填空题) <p>原始数据的样本数量为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>10000</strong></li></ul></li></ul><h4 id="_2-填空题-原始数据的特征维度为" tabindex="-1"><a class="header-anchor" href="#_2-填空题-原始数据的特征维度为"><span>2.(填空题) <p>原始数据的特征维度为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>64</strong></li></ul></li></ul><h4 id="_3-填空题-特征的第1个维度的均值是-请四舍五入保留4位小数" tabindex="-1"><a class="header-anchor" href="#_3-填空题-特征的第1个维度的均值是-请四舍五入保留4位小数"><span>3.(填空题) <p>特征的第1个维度的均值是？（请四舍五入保留4位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.0081</strong></li></ul></li></ul><h4 id="_4-填空题-特征的第1个维度的标准差是-请四舍五入保留4位小数" tabindex="-1"><a class="header-anchor" href="#_4-填空题-特征的第1个维度的标准差是-请四舍五入保留4位小数"><span>4.(填空题) <p>特征的第1个维度的标准差是？（请四舍五入保留4位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.9992</strong></li></ul></li></ul><h4 id="_5-填空题-pca的目标维度为" tabindex="-1"><a class="header-anchor" href="#_5-填空题-pca的目标维度为"><span>5.(填空题) <p>PCA的目标维度为？</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>63</strong></li></ul></li></ul><h4 id="_6-填空题-pca的降维矩阵的第一个元素为-请四舍五入保留4位小数" tabindex="-1"><a class="header-anchor" href="#_6-填空题-pca的降维矩阵的第一个元素为-请四舍五入保留4位小数"><span>6.(填空题) <p>PCA的降维矩阵的第一个元素为？（请四舍五入保留4位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.0016</strong></li></ul></li></ul><h4 id="_7-填空题-模型在测试集上的准确率是-请四舍五入保留4位小数" tabindex="-1"><a class="header-anchor" href="#_7-填空题-模型在测试集上的准确率是-请四舍五入保留4位小数"><span>7.(填空题) <p>模型在测试集上的准确率是？（请四舍五入保留4位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.6373</strong></li></ul></li></ul><h4 id="_8-填空题-模型在测试集上的召回率是-请四舍五入保留4位小数" tabindex="-1"><a class="header-anchor" href="#_8-填空题-模型在测试集上的召回率是-请四舍五入保留4位小数"><span>8.(填空题) <p>模型在测试集上的召回率是？（请四舍五入保留4位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.6417</strong></li></ul></li></ul><h4 id="_9-填空题-模型在测试集上的精确率是-请四舍五入保留4位小数" tabindex="-1"><a class="header-anchor" href="#_9-填空题-模型在测试集上的精确率是-请四舍五入保留4位小数"><span>9.(填空题) <p>模型在测试集上的精确率是？（请四舍五入保留4位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.6882</strong></li></ul></li></ul><h4 id="_10-填空题-模型在测试集上的f1值是-请四舍五入保留4位小数" tabindex="-1"><a class="header-anchor" href="#_10-填空题-模型在测试集上的f1值是-请四舍五入保留4位小数"><span>10.(填空题) <p>模型在测试集上的F1值是？（请四舍五入保留4位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.6152</strong></li></ul></li></ul><h4 id="_11-填空题-第一个测试样本的预测类别为" tabindex="-1"><a class="header-anchor" href="#_11-填空题-第一个测试样本的预测类别为"><span>11.(填空题) <p>第一个测试样本的预测类别为？</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>1</strong></li></ul></li></ul><h4 id="_12-填空题-第二个测试样本的预测类别为" tabindex="-1"><a class="header-anchor" href="#_12-填空题-第二个测试样本的预测类别为"><span>12.(填空题) <p>第二个测试样本的预测类别为？</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>1</strong></li></ul></li></ul><h4 id="_13-填空题-第三个测试样本的预测类别为" tabindex="-1"><a class="header-anchor" href="#_13-填空题-第三个测试样本的预测类别为"><span>13.(填空题) <p>第三个测试样本的预测类别为？</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>1</strong></li></ul></li></ul><h3 id="分类阶段性测试一-分类" tabindex="-1"><a class="header-anchor" href="#分类阶段性测试一-分类"><span>分类阶段性测试一-分类</span></a></h3><h4 id="_1-多选题-机器学习三要素是" tabindex="-1"><a class="header-anchor" href="#_1-多选题-机器学习三要素是"><span>1.(多选题) <p>机器学习三要素是？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>模型</p></strong></li><li id="blue-msg"><strong><p>策略</p></strong></li><li id="blue-msg"><strong><p>算法</p></strong></li><li><p>样本</p></li></ul></li></ul><h4 id="_2-判断题-感知器算法的损失函数是误分类点的总数。" tabindex="-1"><a class="header-anchor" href="#_2-判断题-感知器算法的损失函数是误分类点的总数。"><span>2.(判断题) <p>感知器算法的损失函数是误分类点的总数。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_3-填空题-sklearn提供的感知器类是perceptron-该类实例化的时候一个重要的参数是eta0-请问该参数表示什么" tabindex="-1"><a class="header-anchor" href="#_3-填空题-sklearn提供的感知器类是perceptron-该类实例化的时候一个重要的参数是eta0-请问该参数表示什么"><span>3.(填空题) <p>sklearn提供的感知器类是Perceptron，该类实例化的时候一个重要的参数是eta0，请问该参数表示什么？</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>学习率</strong></li></ul></li></ul><h4 id="_4-多选题-下述指标常用来评价分类模型的有哪些" tabindex="-1"><a class="header-anchor" href="#_4-多选题-下述指标常用来评价分类模型的有哪些"><span>4.(多选题) <p>下述指标常用来评价分类模型的有哪些？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>准确率（accuracy）</p></strong></li><li id="blue-msg"><strong><p>精确率（precision）</p></strong></li><li id="blue-msg"><strong><p>召回率（recall）</p></strong></li><li id="blue-msg"><strong><p>F1-值（F1-score）</p></strong></li><li><p>均方误差</p></li></ul></li></ul><h4 id="_5-段落说明-现有10个样本-6个阳性-positive-4个阴性-negative-。模型分别将2个阳性和1个阴性样本预测错误-其余样本均预测正确。请根据该数据-完成下述四个题目。" tabindex="-1"><a class="header-anchor" href="#_5-段落说明-现有10个样本-6个阳性-positive-4个阴性-negative-。模型分别将2个阳性和1个阴性样本预测错误-其余样本均预测正确。请根据该数据-完成下述四个题目。"><span>5.(段落说明) <p>现有10个样本，6个阳性（positive），4个阴性（negative）。模型分别将2个阳性和1个阴性样本预测错误，其余样本均预测正确。请根据该数据，完成下述四个题目。</p></span></a></h4><ul><li>答案: <ul><li>暂无答案</li></ul></li></ul><h4 id="_6-填空题-模型的准确率-accuracy-是多少-保留两位小数" tabindex="-1"><a class="header-anchor" href="#_6-填空题-模型的准确率-accuracy-是多少-保留两位小数"><span>6.(填空题) <p>模型的准确率（accuracy）是多少？（保留两位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.70</strong></li></ul></li></ul><h4 id="_7-填空题-模型的精确率-precision-是多少-保留两位小数" tabindex="-1"><a class="header-anchor" href="#_7-填空题-模型的精确率-precision-是多少-保留两位小数"><span>7.(填空题) <p>模型的精确率（precision）是多少？（保留两位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.80</strong></li></ul></li></ul><h4 id="_8-填空题-模型的召回率-recall-是多少-保留两位小数" tabindex="-1"><a class="header-anchor" href="#_8-填空题-模型的召回率-recall-是多少-保留两位小数"><span>8.(填空题) <p>模型的召回率（recall）是多少？（保留两位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.67</strong></li></ul></li></ul><h4 id="_9-填空题-f1-值-f1-score-是多少-保留两位小数" tabindex="-1"><a class="header-anchor" href="#_9-填空题-f1-值-f1-score-是多少-保留两位小数"><span>9.(填空题) <p>F1-值（F1-score）是多少？（保留两位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.73</strong></li></ul></li></ul><h4 id="_10-单选题-点击率的预测是一个数据比例不平衡问题-比如训练集中样本呈阴性的比例为99-阳性的比例是1-如果我们用这种数据建立模型并使得训练集的准确率高达99-。下列说法正确的是" tabindex="-1"><a class="header-anchor" href="#_10-单选题-点击率的预测是一个数据比例不平衡问题-比如训练集中样本呈阴性的比例为99-阳性的比例是1-如果我们用这种数据建立模型并使得训练集的准确率高达99-。下列说法正确的是"><span>10.(单选题) <p>点击率的预测是一个数据比例不平衡问题（比如训练集中样本呈阴性的比例为99%，阳性的比例是1%），如果我们用这种数据建立模型并使得训练集的准确率高达99%。下列说法正确的是</p></span></a></h4><ul><li>选项: <ul><li>模型的准确率非常高，我们不需要进一步探索</li><li><p>不能确定模型是否好，应该进一步探讨精确率（precision），如果精确率高，说明模型好。</p></li><li><p>训练样本中阳性和阴性样本的比例不影响模型的性能。</p></li><li id="blue-msg"><strong><p>不能确定模型是否好，应该进一步探讨召回率（recall），如果召回率低，说明模型不好，需要重新考虑。</p></strong></li></ul></li></ul><h4 id="_11-单选题-下列关于支持向量机模型叙述错误的是" tabindex="-1"><a class="header-anchor" href="#_11-单选题-下列关于支持向量机模型叙述错误的是"><span>11.(单选题) <p>下列关于支持向量机模型叙述错误的是？</p></span></a></h4><ul><li>选项: <ul><li><p>对偶问题的解中非零的alpha对应的样本是支持向量。</p></li><li id="blue-msg"><strong><p>将不是支持向量的样本去掉后，使用相同参数重新求得的超平面可能会不同。</p></strong></li><li><p>当惩罚系数C趋于无穷大时，软间隔最大化问题会退化为硬间隔最大化问题。</p></li><li><p>惩罚系数C越小，间隔越大，模型的泛化性能越差。</p></li></ul></li></ul><h4 id="_12-单选题-支持向量机的损失函数是" tabindex="-1"><a class="header-anchor" href="#_12-单选题-支持向量机的损失函数是"><span>12.(单选题) <p>支持向量机的损失函数是？</p></span></a></h4><ul><li>选项: <ul><li><p>0-1损失函数</p></li><li><p>交叉熵损失函数</p></li><li><p>KL-散度</p></li><li id="blue-msg"><strong><p>合页损失函数</p></strong></li></ul></li></ul><h4 id="_13-判断题-线性不可分问题不能使用支持向量机模型求解。" tabindex="-1"><a class="header-anchor" href="#_13-判断题-线性不可分问题不能使用支持向量机模型求解。"><span>13.(判断题) <p>线性不可分问题不能使用支持向量机模型求解。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_14-单选题-sklearn中用支持向量机分类的类名是svc-该类默认使用的核是" tabindex="-1"><a class="header-anchor" href="#_14-单选题-sklearn中用支持向量机分类的类名是svc-该类默认使用的核是"><span>14.(单选题) <p>sklearn中用支持向量机分类的类名是SVC，该类默认使用的核是？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>径向基核函数</p></strong></li><li><p>多项式核函数</p></li><li><p>线性核函数</p></li><li><p>Sigmoid核函数</p></li></ul></li></ul><h4 id="_15-单选题-下列关于多类分类问题-叙述错误的是" tabindex="-1"><a class="header-anchor" href="#_15-单选题-下列关于多类分类问题-叙述错误的是"><span>15.(单选题) <p>下列关于多类分类问题，叙述错误的是</p></span></a></h4><ul><li>选项: <ul><li><p>多类分类问题可以转化为二分类问题</p></li><li><p>one-versus-rest方法可以将多类分类问题转化为二分类问题，但是存在训练样本不平衡的问题。</p></li><li id="blue-msg"><strong><p>one-versus-one方法可以将多类分类问题转化为二分类问题，与one-versus-rest方法的计算量相当</p></strong></li><li><p>one-versus-one方法通常使用投票原则预测分类结果。</p></li></ul></li></ul><h4 id="_16-单选题-下列算法属于生成式模型的是" tabindex="-1"><a class="header-anchor" href="#_16-单选题-下列算法属于生成式模型的是"><span>16.(单选题) <p>下列算法属于生成式模型的是？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>朴素贝叶斯</p></strong></li><li><p>支持向量机</p></li><li><p>感知器算法</p></li><li><p>决策树</p></li></ul></li></ul><h4 id="_17-单选题-下列关于朴素贝叶斯叙述错误的是" tabindex="-1"><a class="header-anchor" href="#_17-单选题-下列关于朴素贝叶斯叙述错误的是"><span>17.(单选题) <p>下列关于朴素贝叶斯叙述错误的是？</p></span></a></h4><ul><li>选项: <ul><li><p>朴素贝叶斯模型的核心假设是“在类别已知的情况下，特征条件独立”。</p></li><li id="blue-msg"><strong><p>朴素贝叶斯模型无法解决连续特征的分类问题。</p></strong></li><li><p>朴素贝叶斯常用于文本分类。</p></li><li><p>拉普拉斯平滑可以有效解决零概率问题。</p></li></ul></li></ul><h4 id="_18-单选题-sklearn中用于分类任务的k-近邻算法的类是kneighborclassifier-下述那个参数是算法中的k" tabindex="-1"><a class="header-anchor" href="#_18-单选题-sklearn中用于分类任务的k-近邻算法的类是kneighborclassifier-下述那个参数是算法中的k"><span>18.(单选题) <p>sklearn中用于分类任务的K-近邻算法的类是KNeighborClassifier，下述那个参数是算法中的K？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>n_neighbors</p></strong></li><li><p>metric</p></li><li><p>p</p></li><li><p>weights</p></li></ul></li></ul><h4 id="_19-判断题-k-近邻算法中的超参数k太大和太小对模型都有影响-不同的问题应该选择合适的k。" tabindex="-1"><a class="header-anchor" href="#_19-判断题-k-近邻算法中的超参数k太大和太小对模型都有影响-不同的问题应该选择合适的k。"><span>19.(判断题) <p>K-近邻算法中的超参数K太大和太小对模型都有影响，不同的问题应该选择合适的K。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_20-判断题-kd-树中的k和k-近邻中的k都是表示满足特定条件的样本个数。" tabindex="-1"><a class="header-anchor" href="#_20-判断题-kd-树中的k和k-近邻中的k都是表示满足特定条件的样本个数。"><span>20.(判断题) <p>KD-树中的K和K-近邻中的K都是表示满足特定条件的样本个数。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_21-判断题-kd-树和ball-树都是为了提升k-近邻算法查找k个近邻样本的效率而设计的数据结构。与暴力搜索相比-它们在特征维度较小时有明显优势。" tabindex="-1"><a class="header-anchor" href="#_21-判断题-kd-树和ball-树都是为了提升k-近邻算法查找k个近邻样本的效率而设计的数据结构。与暴力搜索相比-它们在特征维度较小时有明显优势。"><span>21.(判断题) <p>KD-树和Ball-树都是为了提升K-近邻算法查找K个近邻样本的效率而设计的数据结构。与暴力搜索相比，它们在特征维度较小时有明显优势。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_22-多选题-下列选项中关于k-近邻算法叙述正确的有" tabindex="-1"><a class="header-anchor" href="#_22-多选题-下列选项中关于k-近邻算法叙述正确的有"><span>22.(多选题) <p>下列选项中关于K-近邻算法叙述正确的有</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>K-近邻算法没有明显的训练过程，计算量主要体现在测试阶段。</p></strong></li><li><p>用K-近邻算法分类，预测速度与训练样本多少无关，只与测试样本的数量有关系。</p></li><li><p>K-近邻算法的运算速度与特征的维度无关。</p></li><li id="blue-msg"><strong><p>在使用sklearn中的K-近邻算法时，如果选择了KD-树或Ball-树等数据结构，fit阶段主要用来构建相应的数据结构。</p></strong></li></ul></li></ul><h4 id="_23-多选题-关于决策树-下列说法正确的有" tabindex="-1"><a class="header-anchor" href="#_23-多选题-关于决策树-下列说法正确的有"><span>23.(多选题) <p>关于决策树，下列说法正确的有</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>构建决策树的关键是确定划分属性。</p></strong></li><li><p>决策树越深模型的分类效果越好。</p></li><li id="blue-msg"><strong><p>如果使用信息增益确定最优划分属性，应该选择信息增益大的属性。</p></strong></li><li><p>如果使用基尼指数确定最优划分属性，应该选择基尼指数大的属性。</p></li></ul></li></ul><h4 id="_24-单选题-用决策树分类时-如果训练集规模很大-那么下面哪种方式比较合理" tabindex="-1"><a class="header-anchor" href="#_24-单选题-用决策树分类时-如果训练集规模很大-那么下面哪种方式比较合理"><span>24.(单选题) <p>用决策树分类时，如果训练集规模很大，那么下面哪种方式比较合理？</p></span></a></h4><ul><li>选项: <ul><li><p>降低特征的维度</p></li><li><ol start="2"><li>增加学习率</li></ol></li><li id="blue-msg"><strong><p>3. 减少树的深度</p></strong></li><li><p>挑选少量样本来训练</p></li></ul></li></ul><h4 id="_25-多选题-决策树剪枝的主要目的是" tabindex="-1"><a class="header-anchor" href="#_25-多选题-决策树剪枝的主要目的是"><span>25.(多选题) <p>决策树剪枝的主要目的是？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>降低过拟合风险</p></strong></li><li><p>降低欠拟合风险</p></li><li><p>提高模型在训练集的准确率</p></li><li id="blue-msg"><strong><p>提高模型的泛化能力</p></strong></li></ul></li></ul><h4 id="_26-多选题-经典决策树有id3-c4-5-cart等-下列选项中关于这些算法叙述正确的有" tabindex="-1"><a class="header-anchor" href="#_26-多选题-经典决策树有id3-c4-5-cart等-下列选项中关于这些算法叙述正确的有"><span>26.(多选题) <p>经典决策树有ID3，C4.5，CART等，下列选项中关于这些算法叙述正确的有</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>ID3没有考虑连续特征。</p></strong></li><li id="blue-msg"><strong><p>ID3使用信息增益确定划分属性。</p></strong></li><li id="blue-msg"><strong><p>C4.5使用增益率确定划分属性。</p></strong></li><li id="blue-msg"><strong><p>CART生成的树是二叉树，使用了基尼指数确定划分属性。</p></strong></li><li id="blue-msg"><strong><p>C4.5和CART都可以处理连续属性，都考虑了剪枝，都考虑了缺失值的处理。</p></strong></li><li><p>构建相同深度的决策树，CART比C4.5的运算量大。</p></li></ul></li></ul><h4 id="_27-多选题-下列选项中-哪些算法使用串行策略-通过提升的方式-由若干弱分类器构建出强分类器" tabindex="-1"><a class="header-anchor" href="#_27-多选题-下列选项中-哪些算法使用串行策略-通过提升的方式-由若干弱分类器构建出强分类器"><span>27.(多选题) <p>下列选项中，哪些算法使用串行策略，通过提升的方式，由若干弱分类器构建出强分类器？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>AdaBoost</p></strong></li><li id="blue-msg"><strong><p>梯度提升树</p></strong></li><li><p>决策树</p></li><li><p>Bagging</p></li></ul></li></ul><h4 id="_28-多选题-下列选项中-关于adaboost算法描述正确的有" tabindex="-1"><a class="header-anchor" href="#_28-多选题-下列选项中-关于adaboost算法描述正确的有"><span>28.(多选题) <p>下列选项中，关于AdaBoost算法描述正确的有？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>AdBoost算法通过调整样本的分布，使得当前的弱分类器会优先将分布值大的样本分对。</p></strong></li><li id="blue-msg"><strong><p>AdaBoost算法是向前分步算法的特例。</p></strong></li><li id="blue-msg"><strong><p>在sklearn中，用于分类的AdaBoost算法对应的类是AdaBoostClassifier，其中参数n_estimators是弱分类器个数。</p></strong></li><li><p>AdaBoost算法很好地体现了好而不同的策略。</p></li></ul></li></ul><h4 id="_29-多选题-下列选项中-关于bagging-叙述正确的有" tabindex="-1"><a class="header-anchor" href="#_29-多选题-下列选项中-关于bagging-叙述正确的有"><span>29.(多选题) <p>下列选项中，关于Bagging，叙述正确的有？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>在测试阶段，Bagging在学习到的基学习器中通过投票规则确定最终分类结果。</p></strong></li><li id="blue-msg"><strong><p>Bagging通过Bootstrap重采样的方式实现样本扰动，进而使各基学习器具有差异性。</p></strong></li><li id="blue-msg"><strong><p>在sklearn中，用于分类的Bagging算法对应的类是BaggingClassifier，其中参数n_estimators是基学习器的个数。</p></strong></li><li><p>Bootstrap重采样保证了所有训练样本都将被用来训练某个基学习器。</p></li></ul></li></ul><h4 id="_30-单选题-bootstrap-数据的含义是" tabindex="-1"><a class="header-anchor" href="#_30-单选题-bootstrap-数据的含义是"><span>30.(单选题) <p>bootstrap 数据的含义是：</p></span></a></h4><ul><li>选项: <ul><li><p>有放回的从整体M中抽样m个特征</p></li><li><p>无放回的从整体M中抽样m个特征</p></li><li id="blue-msg"><strong><p>有放回的从整体N中抽样n个样本</p></strong></li><li><p>无放回的从整体N中抽样n个样本</p></li></ul></li></ul><h4 id="_31-多选题-下列选项中-关于随机森林叙述正确的有" tabindex="-1"><a class="header-anchor" href="#_31-多选题-下列选项中-关于随机森林叙述正确的有"><span>31.(多选题) <p>下列选项中，关于随机森林叙述正确的有？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>随机森林通过样本扰动和属性扰动使每棵决策树具有差异性。</p></strong></li><li id="blue-msg"><strong><p>大多数情况下，随机森林的性能优于Bagging。</p></strong></li><li><p>随机森林很好地使用了分而治之的策略。</p></li><li><p>构建随机森林时，随机选取属性个数的参数k无关紧要，该参数的大小对模型的性能影响不大。</p></li></ul></li></ul><h4 id="_32-段落说明-现根据以下数据要构建是否放贷的决策树。在此背景下-完成后续题目-42-51-。结果保留两位小数。" tabindex="-1"><a class="header-anchor" href="#_32-段落说明-现根据以下数据要构建是否放贷的决策树。在此背景下-完成后续题目-42-51-。结果保留两位小数。"><span>32.(段落说明) <p>现根据以下数据要构建是否放贷的决策树。在此背景下，完成后续题目（42-51）。结果保留两位小数。</p></span></a></h4><p> </p><table style="border-collapse:collapse;width:99.6425%;height:171px;" border="1"><tbody><tr style="height:19px;"><td style="width:19.6644%;height:19px;">编号</td><td style="width:19.6644%;height:19px;">有工作</td><td style="width:19.6644%;height:19px;">有房产</td><td style="width:19.6644%;height:19px;">信贷情况</td><td style="width:19.7765%;height:19px;">放贷</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">1</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">好</td><td style="width:19.7765%;height:19px;">是</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">2</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">非常好</td><td style="width:19.7765%;height:19px;">是</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">3</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">非常好</td><td style="width:19.7765%;height:19px;">是</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">4</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">好</td><td style="width:19.7765%;height:19px;">是</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">5</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">一般</td><td style="width:19.7765%;height:19px;">否</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">6</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">好</td><td style="width:19.7765%;height:19px;">否</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">7</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">一般</td><td style="width:19.7765%;height:19px;">否</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">8</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">一般</td><td style="width:19.7765%;height:19px;">否</td></tr></tbody></table><ul><li>答案: <ul><li>暂无答案</li></ul></li></ul><h4 id="_33-填空题-样本集的信息熵为" tabindex="-1"><a class="header-anchor" href="#_33-填空题-样本集的信息熵为"><span>33.(填空题) <p>样本集的信息熵为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>1.00</p></strong></li></ul></li></ul><h4 id="_34-填空题-属性-有工作-的取值为-是-的样本集的熵为" tabindex="-1"><a class="header-anchor" href="#_34-填空题-属性-有工作-的取值为-是-的样本集的熵为"><span>34.(填空题) <p>属性“有工作”的取值为“是”的样本集的熵为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.92</strong></li></ul></li></ul><h4 id="_35-填空题-属性-有工作-的取值为-否-的样本集的熵为" tabindex="-1"><a class="header-anchor" href="#_35-填空题-属性-有工作-的取值为-否-的样本集的熵为"><span>35.(填空题) <p>属性“有工作”的取值为“否”的样本集的熵为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.97</strong></li></ul></li></ul><h4 id="_36-填空题-属性-有工作-的条件熵为" tabindex="-1"><a class="header-anchor" href="#_36-填空题-属性-有工作-的条件熵为"><span>36.(填空题) <p>属性“有工作”的条件熵为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.95</strong></li></ul></li></ul><h4 id="_37-填空题-属性-有工作-的信息增益为" tabindex="-1"><a class="header-anchor" href="#_37-填空题-属性-有工作-的信息增益为"><span>37.(填空题) <p>属性“有工作”的信息增益为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.05</strong></li></ul></li></ul><h4 id="_38-填空题-属性-有房产-的条件熵为" tabindex="-1"><a class="header-anchor" href="#_38-填空题-属性-有房产-的条件熵为"><span>38.(填空题) <p>属性“有房产”的条件熵为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.69</strong></li></ul></li></ul><h4 id="_39-填空题-属性-有房产-的信息增益为" tabindex="-1"><a class="header-anchor" href="#_39-填空题-属性-有房产-的信息增益为"><span>39.(填空题) <p>属性“有房产”的信息增益为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.31</strong></li></ul></li></ul><h4 id="_40-填空题-属性-信贷情况-的条件熵为" tabindex="-1"><a class="header-anchor" href="#_40-填空题-属性-信贷情况-的条件熵为"><span>40.(填空题) <p>属性“信贷情况”的条件熵为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.34</strong></li></ul></li></ul><h4 id="_41-填空题-属性-信贷情况-的信息增益为" tabindex="-1"><a class="header-anchor" href="#_41-填空题-属性-信贷情况-的信息增益为"><span>41.(填空题) <p>属性“信贷情况”的信息增益为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.66</strong></li></ul></li></ul><h4 id="_42-填空题-根节点的划分属性是" tabindex="-1"><a class="header-anchor" href="#_42-填空题-根节点的划分属性是"><span>42.(填空题) <p>根节点的划分属性是</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>信贷情况</strong></li></ul></li></ul><h4 id="_43-段落说明-现根据以下数据-使用朴素贝叶斯预测新样本-是-是-好-的放贷情况。请完成下述题目-53-61-结果保留两位小数。" tabindex="-1"><a class="header-anchor" href="#_43-段落说明-现根据以下数据-使用朴素贝叶斯预测新样本-是-是-好-的放贷情况。请完成下述题目-53-61-结果保留两位小数。"><span>43.(段落说明) <p>现根据以下数据，使用朴素贝叶斯预测新样本（是，是，好）的放贷情况。请完成下述题目（53-61），结果保留两位小数。</p></span></a></h4><p> </p><table style="border-collapse:collapse;width:99.6425%;height:171px;" border="1"><tbody><tr style="height:19px;"><td style="width:19.6644%;height:19px;">编号</td><td style="width:19.6644%;height:19px;">有工作</td><td style="width:19.6644%;height:19px;">有房产</td><td style="width:19.6644%;height:19px;">信贷情况</td><td style="width:19.7765%;height:19px;">放贷</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">1</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">好</td><td style="width:19.7765%;height:19px;">是</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">2</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">非常好</td><td style="width:19.7765%;height:19px;">是</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">3</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">非常好</td><td style="width:19.7765%;height:19px;">是</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">4</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">好</td><td style="width:19.7765%;height:19px;">是</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">5</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">一般</td><td style="width:19.7765%;height:19px;">否</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">6</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">好</td><td style="width:19.7765%;height:19px;">否</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">7</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">一般</td><td style="width:19.7765%;height:19px;">否</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">8</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">一般</td><td style="width:19.7765%;height:19px;">否</td></tr></tbody></table><p> </p><ul><li>答案: <ul><li>暂无答案</li></ul></li></ul><h4 id="_44-填空题-p-y-是" tabindex="-1"><a class="header-anchor" href="#_44-填空题-p-y-是"><span>44.(填空题) <p>P(Y=是)=？</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>0.50</p></strong></li></ul></li></ul><h4 id="_45-填空题-p-有工作-是-y-是" tabindex="-1"><a class="header-anchor" href="#_45-填空题-p-有工作-是-y-是"><span>45.(填空题) <p>P(有工作=是|Y=是)=？</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>0.50</p></strong></li></ul></li></ul><h4 id="_46-填空题-p-有房产-是-y-是" tabindex="-1"><a class="header-anchor" href="#_46-填空题-p-有房产-是-y-是"><span>46.(填空题) <p><span style="display:inline !important;float:none;background-color:#ffffff;color:#000000;font-family:Roboto,Helvetica,Arial,sans-serif;font-size:inherit;font-size-adjust:none;font-stretch:inherit;font-style:inherit;font-variant:inherit;font-weight:400;letter-spacing:normal;line-height:inherit;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;">P(有房产=是|Y=是)=？</span></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>0.50</p></strong></li></ul></li></ul><h4 id="_47-填空题-p-信贷情况-好-y-是" tabindex="-1"><a class="header-anchor" href="#_47-填空题-p-信贷情况-好-y-是"><span>47.(填空题) <p><span style="display:inline !important;float:none;background-color:#ffffff;color:#000000;font-family:Roboto,Helvetica,Arial,sans-serif;font-size:inherit;font-size-adjust:none;font-stretch:inherit;font-style:inherit;font-variant:inherit;font-weight:400;letter-spacing:normal;line-height:inherit;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;">P(信贷情况=好|Y=是)=？</span></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>0.50</p></strong></li></ul></li></ul><h4 id="_48-填空题-p-y-否" tabindex="-1"><a class="header-anchor" href="#_48-填空题-p-y-否"><span>48.(填空题) <p><span style="display:inline !important;float:none;background-color:#ffffff;color:#000000;font-family:Roboto,Helvetica,Arial,sans-serif;font-size:inherit;font-size-adjust:none;font-stretch:inherit;font-style:inherit;font-variant:inherit;font-weight:400;letter-spacing:normal;line-height:inherit;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;">P(Y=否)=？</span></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>0.50</p></strong></li></ul></li></ul><h4 id="_49-填空题-p-有工作-是-y-否" tabindex="-1"><a class="header-anchor" href="#_49-填空题-p-有工作-是-y-否"><span>49.(填空题) <p><span style="display:inline !important;float:none;background-color:#ffffff;color:#000000;font-family:Roboto,Helvetica,Arial,sans-serif;font-size:inherit;font-size-adjust:none;font-stretch:inherit;font-style:inherit;font-variant:inherit;font-weight:400;letter-spacing:normal;line-height:inherit;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;">P(有工作=是|Y=否)=？</span></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>0.25</p></strong></li></ul></li></ul><h4 id="_50-填空题-p-有房产-是-y-否" tabindex="-1"><a class="header-anchor" href="#_50-填空题-p-有房产-是-y-否"><span>50.(填空题) <p><span style="display:inline !important;float:none;background-color:#ffffff;color:#000000;font-family:Roboto,Helvetica,Arial,sans-serif;font-size:inherit;font-size-adjust:none;font-stretch:inherit;font-style:inherit;font-variant:inherit;font-weight:400;letter-spacing:normal;line-height:inherit;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;">P(有房产=是|Y=否)=？</span></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>0.00</p></strong></li></ul></li></ul><h4 id="_51-填空题-p-信贷情况-好-y-否" tabindex="-1"><a class="header-anchor" href="#_51-填空题-p-信贷情况-好-y-否"><span>51.(填空题) <p><span style="display:inline !important;float:none;background-color:#ffffff;color:#000000;font-family:Roboto,Helvetica,Arial,sans-serif;font-size:inherit;font-size-adjust:none;font-stretch:inherit;font-style:inherit;font-variant:inherit;font-weight:400;letter-spacing:normal;line-height:inherit;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;">P(信贷情况=好|Y=否)=？</span></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>0.25</p></strong></li></ul></li></ul><h4 id="_52-单选题-根据上述计算结果-样本-是-是-好-是否放贷" tabindex="-1"><a class="header-anchor" href="#_52-单选题-根据上述计算结果-样本-是-是-好-是否放贷"><span>52.(单选题) <p>根据上述计算结果，<span style="display:inline !important;float:none;background-color:#ffffff;color:#000000;font-family:Roboto,Helvetica,Arial,sans-serif;font-size:inherit;font-size-adjust:none;font-stretch:inherit;font-style:inherit;font-variant:inherit;font-weight:400;letter-spacing:normal;line-height:inherit;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;">样本（是，是，好）是否放贷？</span></p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>是</p></strong></li><li><p>否</p></li><li><p>无法确定</p></li></ul></li></ul><h4 id="_53-段落说明-现有如下样本" tabindex="-1"><a class="header-anchor" href="#_53-段落说明-现有如下样本"><span>53.(段落说明) <p>现有如下样本：</p></span></a></h4><table style="border-collapse:collapse;width:16.0795%;height:105px;" border="1"><tbody><tr style="height:21px;"><td style="width:33.4507%;height:21px;">x1</td><td style="width:33.4507%;height:21px;">x2</td><td style="width:33.4507%;height:21px;">y</td></tr><tr style="height:21px;"><td style="width:33.4507%;height:21px;">0</td><td style="width:33.4507%;height:21px;">1</td><td style="width:33.4507%;height:21px;">+1</td></tr><tr style="height:21px;"><td style="width:33.4507%;height:21px;">0</td><td style="width:33.4507%;height:21px;">2</td><td style="width:33.4507%;height:21px;">+1</td></tr><tr style="height:21px;"><td style="width:33.4507%;height:21px;">1</td><td style="width:33.4507%;height:21px;">0</td><td style="width:33.4507%;height:21px;">-1</td></tr><tr style="height:21px;"><td style="width:33.4507%;height:21px;">2</td><td style="width:33.4507%;height:21px;">0</td><td style="width:33.4507%;height:21px;">-1</td></tr></tbody></table><p>使用SVM得到分类超平面：w1x1+w2x2+b=0.</p><p>请完成下列问题（63-66）。结果保留两位小数。</p><ul><li>答案: <ul><li>暂无答案</li></ul></li></ul><h4 id="_54-填空题-w1" tabindex="-1"><a class="header-anchor" href="#_54-填空题-w1"><span>54.(填空题) <p>w1=?</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>-1.00</p></strong></li></ul></li></ul><h4 id="_55-填空题-w2" tabindex="-1"><a class="header-anchor" href="#_55-填空题-w2"><span>55.(填空题) <p>w2=?</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>1.00</p></strong></li></ul></li></ul><h4 id="_56-填空题-b" tabindex="-1"><a class="header-anchor" href="#_56-填空题-b"><span>56.(填空题) <p>b=?</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>0.00</p></strong></li></ul></li></ul><h4 id="_57-单选题-利用上述模型进行分类-样本-2-1-的分类结果是" tabindex="-1"><a class="header-anchor" href="#_57-单选题-利用上述模型进行分类-样本-2-1-的分类结果是"><span>57.(单选题) <p>利用上述模型进行分类，样本(2,1)的分类结果是？</p></span></a></h4><ul><li>选项: <ul><li><p>+1</p></li><li id="blue-msg"><strong><p>-1</p></strong></li><li><p>无法确定。</p></li></ul></li></ul></div><!----><!----><!----></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">最近更新</span><time class="vp-meta-info" datetime="2025-06-17T09:36:40.000Z" data-allow-mismatch>2025/6/17 09:36</time></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: 1095370199@qq.com">KurimulaAiri</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/art/other/jiqixuexibiji.html" aria-label="机器学习复习笔记"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><VPIcon icon="earth-americas"></VPIcon>机器学习复习笔记</div></a><a class="route-link auto-link next" href="/art/other/Test.html" aria-label="测试用"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">测试用<VPIcon icon="code"></VPIcon></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer"><a href='//beian.miit.gov.cn'>闽ICP备2025092620号-1</a> | <a href='//icp.gov.moe/?keyword=20250596' target='_blank'>萌ICP备20250596号</a></div><div class="vp-copyright">Copyright © 2025 KurimulaAiri </div></footer></div><!--]--><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/assets/app-C0fdAW9E.js" defer></script>
  </body>
</html>
