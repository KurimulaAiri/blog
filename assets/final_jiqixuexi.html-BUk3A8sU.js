import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as t,d as i,a as s,o as n}from"./app-KBm1dPQ3.js";const e={};function r(p,l){return n(),t("div",null,l[0]||(l[0]=[i('<h3 id="期末随堂测试-数科22级" tabindex="-1"><a class="header-anchor" href="#期末随堂测试-数科22级"><span>期末随堂测试-数科22级</span></a></h3><h4 id="_1-判断题-使用k-means算法聚类-算法执行过程中有可能出现空簇。" tabindex="-1"><a class="header-anchor" href="#_1-判断题-使用k-means算法聚类-算法执行过程中有可能出现空簇。"><span>1.(判断题) <p>使用k-means算法聚类，算法执行过程中有可能出现空簇。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_2-判断题-基于密度的聚类方法dbscan无需指定簇的个数。" tabindex="-1"><a class="header-anchor" href="#_2-判断题-基于密度的聚类方法dbscan无需指定簇的个数。"><span>2.(判断题) <p>基于密度的聚类方法DBSCAN无需指定簇的个数。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_3-判断题-使用基于密度的聚类方法dbscan后-每个样本都会归到某个簇中。" tabindex="-1"><a class="header-anchor" href="#_3-判断题-使用基于密度的聚类方法dbscan后-每个样本都会归到某个簇中。"><span>3.(判断题) <p>使用基于密度的聚类方法DBSCAN后，每个样本都会归到某个簇中。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_4-判断题-使用基于凝聚的层次聚类算法agnes聚类后-每个样本都会归到某个簇中。" tabindex="-1"><a class="header-anchor" href="#_4-判断题-使用基于凝聚的层次聚类算法agnes聚类后-每个样本都会归到某个簇中。"><span>4.(判断题) <p><strong>使用基于凝聚的层次聚类算法</strong><strong>AGNES聚类后，每个样本都会归到某个簇中。</strong></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_5-判断题-基于凝聚的层次聚类算法agnes无需指定簇的个数。" tabindex="-1"><a class="header-anchor" href="#_5-判断题-基于凝聚的层次聚类算法agnes无需指定簇的个数。"><span>5.(判断题) <p><strong>基于凝聚的层次聚类算法</strong><strong>AGNES无需指定簇的个数。</strong></p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_6-判断题-聚类评价指标rand-index和adjusted-rand-index均需要带有标注信息的样本。" tabindex="-1"><a class="header-anchor" href="#_6-判断题-聚类评价指标rand-index和adjusted-rand-index均需要带有标注信息的样本。"><span>6.(判断题) <p>聚类评价指标Rand Index和Adjusted Rand Index均需要带有标注信息的样本。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_7-判断题-聚类评价指标轮廓系数silhouette-coefficient需要带有标注信息的样本。" tabindex="-1"><a class="header-anchor" href="#_7-判断题-聚类评价指标轮廓系数silhouette-coefficient需要带有标注信息的样本。"><span>7.(判断题) <p>聚类评价指标轮廓系数silhouette coefficient需要带有标注信息的样本。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_8-判断题-当无法确定簇的个数k时-可以使用轮廓系数silhouette-coefficient或者平方误差来指导选择合适的k。" tabindex="-1"><a class="header-anchor" href="#_8-判断题-当无法确定簇的个数k时-可以使用轮廓系数silhouette-coefficient或者平方误差来指导选择合适的k。"><span>8.(判断题) <p>当无法确定簇的个数k时，可以使用轮廓系数silhouette coefficient或者平方误差来指导选择合适的k。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_9-判断题-基于凝聚的层次聚类算法agnes的结果与簇间距离的计算方式有关系-不同的距离计算方式可能得到不同的结果。" tabindex="-1"><a class="header-anchor" href="#_9-判断题-基于凝聚的层次聚类算法agnes的结果与簇间距离的计算方式有关系-不同的距离计算方式可能得到不同的结果。"><span>9.(判断题) <p><strong>基于凝聚的层次聚类算法</strong><strong>AGNES的结果与簇间距离的计算方式有关系，不同的距离计算方式可能得到不同的结果。</strong></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_10-单选题-下列关于binarizer-copy-说法正确的是" tabindex="-1"><a class="header-anchor" href="#_10-单选题-下列关于binarizer-copy-说法正确的是"><span>10.(单选题) <p>下列关于Binarizer(copy=)说法正确的是</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>copy=True可以保证在使用该类的过程中，输入数据不会被修改。</p></strong></li><li><p>copy=True没有实质性作用，可以忽略。</p></li><li><p>在使用该类时，输入数据总是不会被 修改。</p></li></ul></li></ul><h4 id="_11-单选题-下列选项中属于无监督学习算法的是" tabindex="-1"><a class="header-anchor" href="#_11-单选题-下列选项中属于无监督学习算法的是"><span>11.(单选题) <p>下列选项中属于无监督学习算法的是？</p></span></a></h4><ul><li>选项: <ul><li><p>SVM</p></li><li><p>随机森林</p></li><li id="blue-msg"><strong><p>PCA</p></strong></li><li><p>LDA</p></li></ul></li></ul><h4 id="_12-判断题-k-均值聚类是寻找平方误差最小的簇划分。" tabindex="-1"><a class="header-anchor" href="#_12-判断题-k-均值聚类是寻找平方误差最小的簇划分。"><span>12.(判断题) <p>k-均值聚类是寻找平方误差最小的簇划分。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_13-判断题-k-均值聚类中的k是指特征的维度。" tabindex="-1"><a class="header-anchor" href="#_13-判断题-k-均值聚类中的k是指特征的维度。"><span>13.(判断题) <p>k-均值聚类中的k是指特征的维度。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_14-判断题-k-均值聚类的结果与初始聚类中心的选取无关。" tabindex="-1"><a class="header-anchor" href="#_14-判断题-k-均值聚类的结果与初始聚类中心的选取无关。"><span>14.(判断题) <p>k-均值聚类的结果与初始聚类中心的选取无关。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_15-单选题-下列选项中关于k-means-说法正确的是" tabindex="-1"><a class="header-anchor" href="#_15-单选题-下列选项中关于k-means-说法正确的是"><span>15.(单选题) <p>下列选项中关于k-means++说法正确的是</p></span></a></h4><ul><li>选项: <ul><li><p>k-means++跟k-means一样，都是聚类算法。</p></li><li id="blue-msg"><strong><p>k-means++是一种挑选初始聚类中心的算法。</p></strong></li><li><p>k-means++是k-means的一种改进，可以解决k-means在大数据情况下速度慢的问题。</p></li><li><p>针对相同的数据集，使用k-means++得到的结果总是相同。</p></li></ul></li></ul><h4 id="_16-单选题-在实际使用k-means算法时-往往需要运行多次-然后根据每次的平方误差选取最优的一次。在使用sklearn时-kmeans类的初始化参数中设置该次数的是" tabindex="-1"><a class="header-anchor" href="#_16-单选题-在实际使用k-means算法时-往往需要运行多次-然后根据每次的平方误差选取最优的一次。在使用sklearn时-kmeans类的初始化参数中设置该次数的是"><span>16.(单选题) <p>在实际使用k-means算法时，往往需要运行多次，然后根据每次的平方误差选取最优的一次。在使用sklearn时，KMeans类的初始化参数中设置该次数的是？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p><strong>n_init </strong></p></strong></li><li><p><strong>init</strong></p></li><li><p><strong>n_clusters</strong><strong></strong></p></li><li><p>max_iter</p></li></ul></li></ul><h4 id="_17-单选题-在使用sklearn时-kmeans类哪个成员变量可以返回最终的聚类中心" tabindex="-1"><a class="header-anchor" href="#_17-单选题-在使用sklearn时-kmeans类哪个成员变量可以返回最终的聚类中心"><span>17.(单选题) <p>在使用sklearn时，KMeans类哪个成员变量可以返回最终的聚类中心？</p></span></a></h4><ul><li>选项: <ul><li><p><strong>inertia_ </strong></p></li><li id="blue-msg"><strong><p><strong>cluster_centers</strong><strong>_</strong> </p></strong></li><li><p><strong>labels_ </strong></p></li><li><p><strong>n_iter_</strong></p></li></ul></li></ul><h4 id="_18-判断题-mini-batch-k-means是k-means的一种改进-可以解决k-means在大数据情况下速度慢的问题。" tabindex="-1"><a class="header-anchor" href="#_18-判断题-mini-batch-k-means是k-means的一种改进-可以解决k-means在大数据情况下速度慢的问题。"><span>18.(判断题) <p><strong>mini batch k-means</strong>是k-means的一种改进，可以解决k-means在大数据情况下速度慢的问题。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_19-单选题-mini-batch-k-mean的核心思想是-每次从所有样本中随机选取一批样本来更新聚类中心。请问sklearn-cluster-minibatchkmeans类中哪个参数是设置每批样本的数量" tabindex="-1"><a class="header-anchor" href="#_19-单选题-mini-batch-k-mean的核心思想是-每次从所有样本中随机选取一批样本来更新聚类中心。请问sklearn-cluster-minibatchkmeans类中哪个参数是设置每批样本的数量"><span>19.(单选题) <p>mini batch k-mean的核心思想是：每次从所有样本中随机选取一批样本来更新聚类中心。请问sklearn.cluster.MiniBatchKMeans类中哪个参数是设置每批样本的数量？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p><strong>batch_size</strong></p></strong></li><li><p><strong>n_clusters</strong><strong></strong></p></li><li><p><strong>n_init </strong></p></li><li><p><strong>init</strong><strong></strong></p></li></ul></li></ul><h4 id="_20-单选题-下列关于k-means算法的运行时间叙述正确的是" tabindex="-1"><a class="header-anchor" href="#_20-单选题-下列关于k-means算法的运行时间叙述正确的是"><span>20.(单选题) <p>下列关于k-means算法的运行时间叙述正确的是</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>运行时间与样本数量有关系，样本量越大，时间越长。</p></strong></li><li><p>运行时间受特征维度影响较大，样本数量几乎没有影响</p></li><li><p>运行时间受样本数量影响较大，特征维度几乎没有影响</p></li></ul></li></ul><h4 id="_21-单选题-回归问题和分类问题的区别是" tabindex="-1"><a class="header-anchor" href="#_21-单选题-回归问题和分类问题的区别是"><span>21.(单选题) <p>回归问题和分类问题的区别是？</p></span></a></h4><ul><li>选项: <ul><li><p>特征不同</p></li><li><p>样本数量不同</p></li><li id="blue-msg"><strong><p>标注不同</p></strong></li><li><p>前者是无监督学习任务，后者是监督学习任务。</p></li></ul></li></ul><h4 id="_22-判断题-用于解决回归问题的knn算法和用于解决分类问题的knn算法的核心部分相同-均需找到与测试样本距离最近的k个训练样本。" tabindex="-1"><a class="header-anchor" href="#_22-判断题-用于解决回归问题的knn算法和用于解决分类问题的knn算法的核心部分相同-均需找到与测试样本距离最近的k个训练样本。"><span>22.(判断题) <p>用于解决回归问题的KNN算法和用于解决分类问题的KNN算法的核心部分相同，均需找到与测试样本距离最近的k个训练样本。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_23-判断题-当样本数量较少时-特别是样本量小于或者接近特征的维度-线性回归的最小二乘法不稳定。" tabindex="-1"><a class="header-anchor" href="#_23-判断题-当样本数量较少时-特别是样本量小于或者接近特征的维度-线性回归的最小二乘法不稳定。"><span>23.(判断题) <p>当样本数量较少时，特别是样本量小于或者接近特征的维度，线性回归的最小二乘法不稳定。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_24-判断题-构建回归树需要考虑如何选择切分变量和切分点。" tabindex="-1"><a class="header-anchor" href="#_24-判断题-构建回归树需要考虑如何选择切分变量和切分点。"><span>24.(判断题) <p>构建回归树需要考虑如何选择切分变量和切分点。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_25-判断题-在涉及目标值标准化的问题中-在计算mse和mae时需要将回归模型的输出做反变换。" tabindex="-1"><a class="header-anchor" href="#_25-判断题-在涉及目标值标准化的问题中-在计算mse和mae时需要将回归模型的输出做反变换。"><span>25.(判断题) <p>在涉及目标值标准化的问题中，在计算MSE和MAE时需要将回归模型的输出做反变换。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_26-判断题-回归问题的提升树算法-通过不断拟合已有模型的误差来学习弱学习器-最终得到强学习器。" tabindex="-1"><a class="header-anchor" href="#_26-判断题-回归问题的提升树算法-通过不断拟合已有模型的误差来学习弱学习器-最终得到强学习器。"><span>26.(判断题) <p>回归问题的提升树算法，通过不断拟合已有模型的误差来学习弱学习器，最终得到强学习器。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_27-判断题-通常把反映数据内在规律的信息叫做特征。" tabindex="-1"><a class="header-anchor" href="#_27-判断题-通常把反映数据内在规律的信息叫做特征。"><span>27.(判断题) <p>通常把反映数据内在规律的信息叫做特征。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_28-多选题-机器学习三要素是" tabindex="-1"><a class="header-anchor" href="#_28-多选题-机器学习三要素是"><span>28.(多选题) <p>机器学习三要素是？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>模型</p></strong></li><li id="blue-msg"><strong><p>策略</p></strong></li><li id="blue-msg"><strong><p>算法</p></strong></li><li><p>数据</p></li></ul></li></ul><h4 id="_29-多选题-用于评价分类模型性能的指标通常有" tabindex="-1"><a class="header-anchor" href="#_29-多选题-用于评价分类模型性能的指标通常有"><span>29.(多选题) <p>用于评价分类模型性能的指标通常有</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>准确率</p></strong></li><li id="blue-msg"><strong><p>精确率</p></strong></li><li id="blue-msg"><strong><p>召回率</p></strong></li><li id="blue-msg"><strong><p>F1-值</p></strong></li><li><p>事件发生的几率</p></li></ul></li></ul><h4 id="_30-单选题-在哪一种距离下-单位圆周是顶点在坐标轴上的正方形" tabindex="-1"><a class="header-anchor" href="#_30-单选题-在哪一种距离下-单位圆周是顶点在坐标轴上的正方形"><span>30.(单选题) <p>在哪一种距离下，单位圆周是顶点在坐标轴上的正方形？</p></span></a></h4><ul><li>选项: <ul><li><p>欧式距离</p></li><li id="blue-msg"><strong><p>曼哈顿距离</p></strong></li><li><p>切比雪夫距离</p></li><li><p>p为任意取值的闵可夫斯基距离</p></li></ul></li></ul><h4 id="_31-判断题-回归是无监督学习。" tabindex="-1"><a class="header-anchor" href="#_31-判断题-回归是无监督学习。"><span>31.(判断题) <p>回归是无监督学习。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_32-判断题-回归与分类的区别是-回归模型输出为连续值-分类模型输出为离散值。" tabindex="-1"><a class="header-anchor" href="#_32-判断题-回归与分类的区别是-回归模型输出为连续值-分类模型输出为离散值。"><span>32.(判断题) <p>回归与分类的区别是：回归模型输出为连续值，分类模型输出为离散值。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_33-单选题-最小二乘回归使用什么损失" tabindex="-1"><a class="header-anchor" href="#_33-单选题-最小二乘回归使用什么损失"><span>33.(单选题) <p>最小二乘回归使用什么损失？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>平方损失</p></strong></li><li><p>合页损失</p></li><li><p>对数损失</p></li><li><p>指数损失</p></li></ul></li></ul><h4 id="_34-单选题-岭回归和lasso的正则项分别是" tabindex="-1"><a class="header-anchor" href="#_34-单选题-岭回归和lasso的正则项分别是"><span>34.(单选题) <p>岭回归和Lasso的正则项分别是？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>L2范数和L1范数</p></strong></li><li><p>L1范数和L2范数</p></li><li><p>L0范数和L1范数</p></li><li><p>L2范数和L0范数</p></li></ul></li></ul><h4 id="_35-单选题-下列哪个算法可以抑制离群点的影响" tabindex="-1"><a class="header-anchor" href="#_35-单选题-下列哪个算法可以抑制离群点的影响"><span>35.(单选题) <p>下列哪个算法可以抑制离群点的影响？</p></span></a></h4><ul><li>选项: <ul><li><p>最小乘回归</p></li><li><p>岭回归</p></li><li><p>Lasso回归</p></li><li id="blue-msg"><strong><p>Huber回归</p></strong></li></ul></li></ul><h4 id="_36-多选题-下列指标用于评价回归模型的有" tabindex="-1"><a class="header-anchor" href="#_36-多选题-下列指标用于评价回归模型的有"><span>36.(多选题) <p>下列指标用于评价回归模型的有</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>均方误差</p></strong></li><li id="blue-msg"><strong><p>平均绝对误差</p></strong></li><li id="blue-msg"><strong><p>决定系数</p></strong></li><li><p>召回率</p></li><li><p>F1值</p></li></ul></li></ul><h4 id="_37-判断题-利用knn算法回归时-选取距离测试样本最小的k个训练样本-然后对这k个近邻目标的值进行平均-得到测试样本的预测值。" tabindex="-1"><a class="header-anchor" href="#_37-判断题-利用knn算法回归时-选取距离测试样本最小的k个训练样本-然后对这k个近邻目标的值进行平均-得到测试样本的预测值。"><span>37.(判断题) <p>利用KNN算法回归时，选取距离测试样本最小的K个训练样本，然后对这K个近邻目标的值进行平均，得到测试样本的预测值。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_38-判断题-在构建回归树时-关键问题是如何选择切分变量和切分点。确定最优切分变量和最优切分点通常使用启发式方法-即先固定切分方向j-确定切分点s-然后" tabindex="-1"><a class="header-anchor" href="#_38-判断题-在构建回归树时-关键问题是如何选择切分变量和切分点。确定最优切分变量和最优切分点通常使用启发式方法-即先固定切分方向j-确定切分点s-然后"><span>38.(判断题) <p>在构建回归树时，关键问题是如何选择切分变量和切分点。确定最优切分变量和最优切分点通常使用启发式方法，即先固定切分方向<em>j</em>，确定切分点<em>s；</em>然后</p></span></a></h4><p>遍历所有<em>j</em>，确定最优切分变量和切分点(<em>j</em>,<em>s</em>)。</p><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_39-判断题-针对回归问题-在构建提升树时-每次迭代是针对残差进行拟合来构建回归树的。" tabindex="-1"><a class="header-anchor" href="#_39-判断题-针对回归问题-在构建提升树时-每次迭代是针对残差进行拟合来构建回归树的。"><span>39.(判断题) <p>针对回归问题，在构建提升树时，每次迭代是针对残差进行拟合来构建回归树的。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_40-单选题-支持向量回归的损失函数是" tabindex="-1"><a class="header-anchor" href="#_40-单选题-支持向量回归的损失函数是"><span>40.(单选题) <p>支持向量回归的损失函数是？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p><strong>epsilon_insensitive</strong></p></strong></li><li><p>平方损失</p></li><li><p>Huber损失</p></li><li><p>指数损失</p></li></ul></li></ul><h4 id="_41-判断题-使用pca降维是无损的。" tabindex="-1"><a class="header-anchor" href="#_41-判断题-使用pca降维是无损的。"><span>41.(判断题) <p>使用PCA降维是无损的。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_42-判断题-pca降维是无监督学习方法。" tabindex="-1"><a class="header-anchor" href="#_42-判断题-pca降维是无监督学习方法。"><span>42.(判断题) <p>PCA降维是无监督学习方法。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_43-判断题-pca的核心思想是投影到方差更大的方向。" tabindex="-1"><a class="header-anchor" href="#_43-判断题-pca的核心思想是投影到方差更大的方向。"><span>43.(判断题) <p>PCA的核心思想是投影到方差更大的方向。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_44-判断题-pca需要先对样本进行中心化处理-即每个样本减去样本均值。" tabindex="-1"><a class="header-anchor" href="#_44-判断题-pca需要先对样本进行中心化处理-即每个样本减去样本均值。"><span>44.(判断题) <p>PCA需要先对样本进行中心化处理，即每个样本减去样本均值。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_45-多选题-在pca降维时-关于目标维度和累积贡献率的关系-下述说法正确的是" tabindex="-1"><a class="header-anchor" href="#_45-多选题-在pca降维时-关于目标维度和累积贡献率的关系-下述说法正确的是"><span>45.(多选题) <p>在PCA降维时，关于目标维度和累积贡献率的关系，下述说法正确的是</p></span></a></h4><ul><li>选项: <ul><li><p>目标维度越大，累积贡献率越小</p></li><li id="blue-msg"><strong><p>目标维度越大，累积贡献率越大</p></strong></li><li><p>累积贡献率和目标维度无关</p></li><li id="blue-msg"><strong><p>当目标维度和特征维度相同时，累积贡献率等于1.</p></strong></li></ul></li></ul><h4 id="_46-判断题-累积贡献率的取值范围是-大于0小于1" tabindex="-1"><a class="header-anchor" href="#_46-判断题-累积贡献率的取值范围是-大于0小于1"><span>46.(判断题) <p>累积贡献率的取值范围是：大于0小于1</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_47-多选题-关于sklearn-decomposition-pca-n-components-中的参数n-components-叙述正确的有" tabindex="-1"><a class="header-anchor" href="#_47-多选题-关于sklearn-decomposition-pca-n-components-中的参数n-components-叙述正确的有"><span>47.(多选题) <p>关于sklearn.decomposition.<strong>PCA</strong>(<strong>n_components)中的参数n_components，叙述正确的有</strong></p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p><strong>n_components可以取大于等于1的整数，此时表示目标维度</strong></p></strong></li><li id="blue-msg"><strong><p><strong>n_components</strong>取值为(0，1]之间的浮点数时，用累积贡献率来决定维数，即目标维度要使的对应的累积贡献率刚好大于等于该值</p></strong></li><li id="blue-msg"><strong><p>默认时无输入，此时n_components=min(样本数，特征数)</p></strong></li><li id="blue-msg"><strong><p>取值为字符串“mle”时, 用MLE算法自己选择一定数量的主成分特征来降维</p></strong></li></ul></li></ul><h4 id="_48-判断题-可以通过sklearn-decomposition-pca-中的成员变量explained-variance-获取协方差矩阵的特征根。" tabindex="-1"><a class="header-anchor" href="#_48-判断题-可以通过sklearn-decomposition-pca-中的成员变量explained-variance-获取协方差矩阵的特征根。"><span>48.(判断题) <p><strong>可以通过sklearn.decomposition.PCA()中的成员变量explained_variance</strong><strong>_，获取协方差矩阵的特征根。</strong></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_49-判断题-可以对sklearn-decomposition-pca-中的成员变量explained-variance-ratio-进行求和-来获取累积贡献率。" tabindex="-1"><a class="header-anchor" href="#_49-判断题-可以对sklearn-decomposition-pca-中的成员变量explained-variance-ratio-进行求和-来获取累积贡献率。"><span>49.(判断题) <p><strong>可以对sklearn.decomposition.PCA()中的成员变量explained_variance_ratio_进行求和</strong><strong>，来获取累积贡献率。</strong></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_50-判断题-可以通过sklearn-decomposition-pca-中的成员变量mean-获取训练样本的均值。" tabindex="-1"><a class="header-anchor" href="#_50-判断题-可以通过sklearn-decomposition-pca-中的成员变量mean-获取训练样本的均值。"><span>50.(判断题) <p> <strong>可以通过sklearn.decomposition.PCA()中的成员变量mean_</strong><strong>，获取训练样本的均值。</strong></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_51-判断题-可以通过sklearn-decomposition-pca-中的成员变量components-获取降维矩阵。" tabindex="-1"><a class="header-anchor" href="#_51-判断题-可以通过sklearn-decomposition-pca-中的成员变量components-获取降维矩阵。"><span>51.(判断题) <p><strong>可以通过sklearn.decomposition.PCA()中的成员变量components_ ，获取降维矩阵。</strong></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_52-判断题-kernelpca是在更高维空间进行降维-所以需要设计低维到高位的投影函数。" tabindex="-1"><a class="header-anchor" href="#_52-判断题-kernelpca是在更高维空间进行降维-所以需要设计低维到高位的投影函数。"><span>52.(判断题) <p>KernelPCA是在更高维空间进行降维，所以需要设计低维到高位的投影函数。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_53-单选题-sklearn中使用核pca的类是" tabindex="-1"><a class="header-anchor" href="#_53-单选题-sklearn中使用核pca的类是"><span>53.(单选题) <p>sklearn中使用核PCA的类是：</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>KernelPCA</p></strong></li><li><p>PCA</p></li><li><p><strong>LinearDiscriminantAnalysis</strong></p></li><li><p>KernelSVM</p></li></ul></li></ul><h4 id="_54-单选题-在sklearn中使用pca和核pca这两个类时-初始化类时-目标维度均使用如下哪个参数指定" tabindex="-1"><a class="header-anchor" href="#_54-单选题-在sklearn中使用pca和核pca这两个类时-初始化类时-目标维度均使用如下哪个参数指定"><span>54.(单选题) <p>在sklearn中使用PCA和核PCA这两个类时，初始化类时，目标维度均使用如下哪个参数指定？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p><strong>n_components</strong></p></strong></li><li><p><strong>kernel</strong></p></li><li><p><strong>gamma</strong></p></li><li><p><strong>degree</strong></p></li></ul></li></ul><h4 id="_55-多选题-在sklearn中-当使用pca类时-如下选项哪些是关于核函数的参数" tabindex="-1"><a class="header-anchor" href="#_55-多选题-在sklearn中-当使用pca类时-如下选项哪些是关于核函数的参数"><span>55.(多选题) <p>在sklearn中，当使用PCA类时，如下选项哪些是关于核函数的参数？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>linear</p></strong></li><li id="blue-msg"><strong><p>poly</p></strong></li><li id="blue-msg"><strong><p>rbf</p></strong></li><li id="blue-msg"><strong><p>sigmoid</p></strong></li></ul></li></ul><h4 id="_56-单选题-在sklearn中-核pca类使用如下哪个参数kernel指定和函数类型" tabindex="-1"><a class="header-anchor" href="#_56-单选题-在sklearn中-核pca类使用如下哪个参数kernel指定和函数类型"><span>56.(单选题) <p><strong>在sklearn中，核PCA类使用如下哪个参数kernel指定和函数类型？</strong></p></span></a></h4><ul><li>选项: <ul><li><p><strong>n_components</strong></p></li><li id="blue-msg"><strong><p><strong>kernel</strong></p></strong></li><li><p><strong>gamma</strong></p></li><li><p><strong>degree</strong></p></li></ul></li></ul><h4 id="_57-判断题-使用核pca时-针对训练集的核矩阵是对称矩阵。" tabindex="-1"><a class="header-anchor" href="#_57-判断题-使用核pca时-针对训练集的核矩阵是对称矩阵。"><span>57.(判断题) <p>使用核PCA时，针对训练集的核矩阵是对称矩阵。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_58-多选题-在核pca的过程中-在训练阶段针对训练集需要完成的步骤有哪些" tabindex="-1"><a class="header-anchor" href="#_58-多选题-在核pca的过程中-在训练阶段针对训练集需要完成的步骤有哪些"><span>58.(多选题) <p>在核PCA的过程中，在训练阶段针对训练集需要完成的步骤有哪些？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>计算核矩阵</p></strong></li><li id="blue-msg"><strong><p>对核矩阵进行中心化处理</p></strong></li><li id="blue-msg"><strong><p>特征值分解，确定投影矩阵</p></strong></li><li><p>通过高维映射确定样本在高维空间中的投影</p></li></ul></li></ul><h4 id="_59-多选题-在核pca的过程中-在测试阶段针对测试集需要完成的步骤有哪些" tabindex="-1"><a class="header-anchor" href="#_59-多选题-在核pca的过程中-在测试阶段针对测试集需要完成的步骤有哪些"><span>59.(多选题) <p>在核PCA的过程中，在测试阶段针对测试集需要完成的步骤有哪些？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>计算测试集对应的核矩阵</p></strong></li><li id="blue-msg"><strong><p>测试集核矩阵中心和</p></strong></li><li id="blue-msg"><strong><p>使用训练阶段确定的投影矩阵，对测试机核矩阵进行投影</p></strong></li><li><p>将结果投影到原始的特征空间</p></li></ul></li></ul><h4 id="_60-判断题-kernelpca是在更高维空间进行降维-所以需要设计低维到高位的投影函数。" tabindex="-1"><a class="header-anchor" href="#_60-判断题-kernelpca是在更高维空间进行降维-所以需要设计低维到高位的投影函数。"><span>60.(判断题) <p>KernelPCA是在更高维空间进行降维，所以需要设计低维到高位的投影函数。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_61-单选题-sklearn中使用核pca的类是" tabindex="-1"><a class="header-anchor" href="#_61-单选题-sklearn中使用核pca的类是"><span>61.(单选题) <p>sklearn中使用核PCA的类是：</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>KernelPCA</p></strong></li><li><p>PCA</p></li><li><p><strong>LinearDiscriminantAnalysis</strong></p></li><li><p>KernelSVM</p></li></ul></li></ul><h4 id="_62-单选题-在sklearn中使用pca和核pca这两个类时-初始化类时-目标维度均使用如下哪个参数指定" tabindex="-1"><a class="header-anchor" href="#_62-单选题-在sklearn中使用pca和核pca这两个类时-初始化类时-目标维度均使用如下哪个参数指定"><span>62.(单选题) <p>在sklearn中使用PCA和核PCA这两个类时，初始化类时，目标维度均使用如下哪个参数指定？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p><strong>n_components</strong></p></strong></li><li><p><strong>kernel</strong></p></li><li><p><strong>gamma</strong></p></li><li><p><strong>degree</strong></p></li></ul></li></ul><h4 id="_63-多选题-在sklearn中-如下选项哪些是关于核pca方法的关于核函数的参数" tabindex="-1"><a class="header-anchor" href="#_63-多选题-在sklearn中-如下选项哪些是关于核pca方法的关于核函数的参数"><span>63.(多选题) <p>在sklearn中，如下选项哪些是关于核PCA方法的关于核函数的参数？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>linear</p></strong></li><li id="blue-msg"><strong><p>poly</p></strong></li><li id="blue-msg"><strong><p>rbf</p></strong></li><li id="blue-msg"><strong><p>sigmoid</p></strong></li></ul></li></ul><h4 id="_64-单选题-在sklearn中-核pca类使用如下哪个参数kernel指定和函数类型" tabindex="-1"><a class="header-anchor" href="#_64-单选题-在sklearn中-核pca类使用如下哪个参数kernel指定和函数类型"><span>64.(单选题) <p><strong>在sklearn中，核PCA类使用如下哪个参数kernel指定和函数类型？</strong></p></span></a></h4><ul><li>选项: <ul><li><p><strong>n_components</strong></p></li><li id="blue-msg"><strong><p><strong>kernel</strong></p></strong></li><li><p><strong>gamma</strong></p></li><li><p><strong>degree</strong></p></li></ul></li></ul><h4 id="_65-判断题-使用核pca时-针对训练集的核矩阵是对称矩阵。" tabindex="-1"><a class="header-anchor" href="#_65-判断题-使用核pca时-针对训练集的核矩阵是对称矩阵。"><span>65.(判断题) <p>使用核PCA时，针对训练集的核矩阵是对称矩阵。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_66-多选题-在核pca的过程中-在训练阶段针对训练集需要完成的步骤有哪些" tabindex="-1"><a class="header-anchor" href="#_66-多选题-在核pca的过程中-在训练阶段针对训练集需要完成的步骤有哪些"><span>66.(多选题) <p>在核PCA的过程中，在训练阶段针对训练集需要完成的步骤有哪些？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>计算核矩阵</p></strong></li><li id="blue-msg"><strong><p>对核矩阵进行中心化处理</p></strong></li><li id="blue-msg"><strong><p>特征值分解，确定投影矩阵</p></strong></li><li><p>通过高维映射确定样本在高维空间中的投影</p></li></ul></li></ul><h4 id="_67-多选题-在核pca的过程中-在测试阶段针对测试集需要完成的步骤有哪些" tabindex="-1"><a class="header-anchor" href="#_67-多选题-在核pca的过程中-在测试阶段针对测试集需要完成的步骤有哪些"><span>67.(多选题) <p>在核PCA的过程中，在测试阶段针对测试集需要完成的步骤有哪些？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>计算测试集对应的核矩阵</p></strong></li><li id="blue-msg"><strong><p>测试集核矩阵中心和</p></strong></li><li id="blue-msg"><strong><p>使用训练阶段确定的投影矩阵，对测试机核矩阵进行投影</p></strong></li><li><p>将结果投影到原始的特征空间</p></li></ul></li></ul><h4 id="_68-多选题-下述降维方法是无监督的有" tabindex="-1"><a class="header-anchor" href="#_68-多选题-下述降维方法是无监督的有"><span>68.(多选题) <p>下述降维方法是无监督的有？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>PCA</p></strong></li><li id="blue-msg"><strong><p>KernelPCA</p></strong></li><li><p>LDA</p></li></ul></li></ul><h4 id="_69-判断题-lda的核心思想是投影后保证类间距离最大化-类内距离最小化。" tabindex="-1"><a class="header-anchor" href="#_69-判断题-lda的核心思想是投影后保证类间距离最大化-类内距离最小化。"><span>69.(判断题) <p>LDA的核心思想是投影后保证类间距离最大化，类内距离最小化。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_70-判断题-pca选择分类性能最好的投影方向。" tabindex="-1"><a class="header-anchor" href="#_70-判断题-pca选择分类性能最好的投影方向。"><span>70.(判断题) <p>PCA选择分类性能最好的投影方向。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_71-单选题-lda降维后的维度需要满足" tabindex="-1"><a class="header-anchor" href="#_71-单选题-lda降维后的维度需要满足"><span>71.(单选题) <p>LDA降维后的维度需要满足？</p></span></a></h4><ul><li>选项: <ul><li><p>小于样本个数即可</p></li><li><p>小于类别数即可</p></li><li><p>可以等于样本个数，也可以等于类别数</p></li><li id="blue-msg"><strong><p>不超过样本个数，同时小于类别数</p></strong></li></ul></li></ul><h4 id="_72-判断题-lda无需对样本中心化处理。" tabindex="-1"><a class="header-anchor" href="#_72-判断题-lda无需对样本中心化处理。"><span>72.(判断题) <p>LDA无需对样本中心化处理。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_73-单选题-用于lda降维的类sklearn-discriminant-analysis-lineardiscriminantanalysis-其哪个参数用于指定目标维度" tabindex="-1"><a class="header-anchor" href="#_73-单选题-用于lda降维的类sklearn-discriminant-analysis-lineardiscriminantanalysis-其哪个参数用于指定目标维度"><span>73.(单选题) <p>用于LDA降维的类sklearn.discriminant_analysis.LinearDiscriminantAnalysis，其哪个参数用于指定目标维度？</p></span></a></h4><ul><li>选项: <ul><li><p><strong style="box-sizing:border-box;color:#212529;font-family:-apple-system,BlinkMacSystemFont,&amp;quot;font-size:16px;font-style:normal;font-variant:normal;font-weight:bold;letter-spacing:normal;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;" data-mce-fragment="1">solver</strong></p></li><li id="blue-msg"><strong><p><span style="display:inline !important;float:none;background-color:#ffffff;color:#212529;font-family:-apple-system,BlinkMacSystemFont,&#39;Segoe UI&#39;,Roboto,&#39;Helvetica Neue&#39;,Arial,&#39;Noto Sans&#39;,sans-serif,&#39;Apple Color Emoji&#39;,&#39;Segoe UI Emoji&#39;,&#39;Segoe UI Symbol&#39;,&#39;Noto Color Emoji&#39;;font-size:16px;font-style:normal;font-variant:normal;font-weight:bold;letter-spacing:normal;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;">n_components</span></p></strong></li><li><p><strong style="box-sizing:border-box;color:#212529;font-family:-apple-system,BlinkMacSystemFont,&amp;quot;font-size:16px;font-style:normal;font-variant:normal;font-weight:bold;letter-spacing:normal;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;" data-mce-fragment="1">covariance_estimator</strong></p></li><li><p><em><span style="display:inline !important;float:none;background-color:#ffffff;color:#212529;font-family:-apple-system,BlinkMacSystemFont,&#39;Segoe UI&#39;,Roboto,&#39;Helvetica Neue&#39;,Arial,&#39;Noto Sans&#39;,sans-serif,&#39;Apple Color Emoji&#39;,&#39;Segoe UI Emoji&#39;,&#39;Segoe UI Symbol&#39;,&#39;Noto Color Emoji&#39;;font-size:16px;font-style:normal;font-variant:normal;font-weight:bold;letter-spacing:normal;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;">store_covariance</span></em></p></li></ul></li></ul><h4 id="_74-单选题-用于lda降维的类sklearn-discriminant-analysis-lineardiscriminantanalysis-其哪个方法用于测试样本的投影" tabindex="-1"><a class="header-anchor" href="#_74-单选题-用于lda降维的类sklearn-discriminant-analysis-lineardiscriminantanalysis-其哪个方法用于测试样本的投影"><span>74.(单选题) <p>用于LDA降维的类sklearn.discriminant_analysis.LinearDiscriminantAnalysis，其哪个方法用于测试样本的投影？</p></span></a></h4><ul><li>选项: <ul><li><p><a class="reference internal" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit_transform" href="https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code></a></p></li><li><p>fit</p></li><li id="blue-msg"><strong><p>transform</p></strong></li><li><p>predict</p></li></ul></li></ul><h4 id="_75-单选题-用于lda降维的类sklearn-discriminant-analysis-lineardiscriminantanalysis-其哪个方法用于预测类别" tabindex="-1"><a class="header-anchor" href="#_75-单选题-用于lda降维的类sklearn-discriminant-analysis-lineardiscriminantanalysis-其哪个方法用于预测类别"><span>75.(单选题) <p>用于LDA降维的类sklearn.discriminant_analysis.LinearDiscriminantAnalysis，其哪个方法用于预测类别？</p></span></a></h4><ul><li>选项: <ul><li><p>fit_transform</p></li><li><p>fit</p></li><li><p>transform</p></li><li id="blue-msg"><strong><p>predict</p></strong></li></ul></li></ul><h4 id="_76-单选题-l1正则化和l2正则化中-哪一个更有让所学参数具有稀疏的趋势" tabindex="-1"><a class="header-anchor" href="#_76-单选题-l1正则化和l2正则化中-哪一个更有让所学参数具有稀疏的趋势"><span>76.(单选题) <p>L1正则化和L2正则化中，哪一个更有让所学参数具有稀疏的趋势？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>L1正则化</p></strong></li><li><p>L2正则化</p></li><li><p>它们没有区别</p></li></ul></li></ul><h4 id="_77-判断题-在回归问题中-对标注-即输出值-做标准化-不影响回归模型的评价指标值。" tabindex="-1"><a class="header-anchor" href="#_77-判断题-在回归问题中-对标注-即输出值-做标准化-不影响回归模型的评价指标值。"><span>77.(判断题) <p>在回归问题中，对标注（即输出值）做标准化，不影响回归模型的评价指标值。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_78-多选题-在回归问题中-对标注-即输出值-做标准化-回归模型的评价指标值改变的是" tabindex="-1"><a class="header-anchor" href="#_78-多选题-在回归问题中-对标注-即输出值-做标准化-回归模型的评价指标值改变的是"><span>78.(多选题) <p>在回归问题中，对标注（即输出值）做标准化，回归模型的评价指标值改变的是？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p><strong>均方误差</strong></p></strong></li><li id="blue-msg"><strong><p><strong>平均绝对误差</strong></p></strong></li><li><p><strong>决定系数</strong></p></li><li><p>召回率</p></li></ul></li></ul><h4 id="_79-判断题-在前馈神经网络中-如果每一层均不使用非线性激活函数-那么该神经网络是一个线性模型。" tabindex="-1"><a class="header-anchor" href="#_79-判断题-在前馈神经网络中-如果每一层均不使用非线性激活函数-那么该神经网络是一个线性模型。"><span>79.(判断题) <p>在前馈神经网络中，如果每一层均不使用非线性激活函数，那么该神经网络是一个线性模型。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_80-判断题-使用前馈神经网络进行推理-是正向传播过程。" tabindex="-1"><a class="header-anchor" href="#_80-判断题-使用前馈神经网络进行推理-是正向传播过程。"><span>80.(判断题) <p>使用前馈神经网络进行推理，是正向传播过程。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_81-判断题-训练前馈神经网络的核心过程是误差反向传播过程。" tabindex="-1"><a class="header-anchor" href="#_81-判断题-训练前馈神经网络的核心过程是误差反向传播过程。"><span>81.(判断题) <p>训练前馈神经网络的核心过程是误差反向传播过程。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_82-单选题-使用如下网络-输入是-1-1-的-输出是多少" tabindex="-1"><a class="header-anchor" href="#_82-单选题-使用如下网络-输入是-1-1-的-输出是多少"><span>82.(单选题) <p>使用如下网络，输入是（1,1）的，输出是多少？</p></span></a></h4><p>其中，激活函数是变异的符号函数，即如果输入是非负数，那么输出为1；否则输出0.</p>',166),s("p",null,[s("img",{src:"//img.ketangpai.com/ketangpai.aliapp.com/1/webroot/Uploads/Download/2025-05-16/68267a587c5c1.png?OSSAccessKeyId=LTAItfPkNIKJFibY&Expires=4900952152&Signature=MwaOrMKTYv52SaIowxgczpQK1TY%3D",width:"428",height:"178",crossOrigin:"anonymous"})],-1),i('<ul><li>选项: <ul><li id="blue-msg"><strong><p>0</p></strong></li><li><p>1</p></li><li><p>-0.5</p></li><li><p>-1.5</p></li></ul></li></ul><h4 id="_83-多选题-在推理阶段-对于给定的输入-一个前馈神经网络的输出结果和以下哪些项有关" tabindex="-1"><a class="header-anchor" href="#_83-多选题-在推理阶段-对于给定的输入-一个前馈神经网络的输出结果和以下哪些项有关"><span>83.(多选题) <p>在推理阶段，对于给定的输入，一个前馈神经网络的输出结果和以下哪些项有关？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>激活函数</p></strong></li><li id="blue-msg"><strong><p>相邻两层之间的权重系数</p></strong></li><li id="blue-msg"><strong><p>每个神经元的偏置</p></strong></li><li><p>学习率</p></li></ul></li></ul><h4 id="_84-多选题-在训练阶段-对于给定的网络结构-最终的模型和以下哪些项有关" tabindex="-1"><a class="header-anchor" href="#_84-多选题-在训练阶段-对于给定的网络结构-最终的模型和以下哪些项有关"><span>84.(多选题) <p>在训练阶段，对于给定的网络结构，最终的模型和以下哪些项有关？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>学习率</p></strong></li><li id="blue-msg"><strong><p>训练轮数（Epoch）</p></strong></li><li id="blue-msg"><strong><p>参数初始化方法</p></strong></li><li id="blue-msg"><strong><p>损失函数</p></strong></li></ul></li></ul><h4 id="_85-判断题-在使用sklearn的数据标准化类的时候-成员函数fit-transform和transform是一样的-没有区别。" tabindex="-1"><a class="header-anchor" href="#_85-判断题-在使用sklearn的数据标准化类的时候-成员函数fit-transform和transform是一样的-没有区别。"><span>85.(判断题) <p>在使用sklearn的数据标准化类的时候，成员函数fit_transform和transform是一样的，没有区别。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_86-判断题-binarizer类中的fit-方法没有实质性作用。" tabindex="-1"><a class="header-anchor" href="#_86-判断题-binarizer类中的fit-方法没有实质性作用。"><span>86.(判断题) <p>Binarizer类中的fit()方法没有实质性作用。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_87-判断题-在测试集上可以使用maxabsscale类的fit-transform-方法。" tabindex="-1"><a class="header-anchor" href="#_87-判断题-在测试集上可以使用maxabsscale类的fit-transform-方法。"><span>87.(判断题) <p>在测试集上可以使用MaxAbsScale类的fit_transform()方法。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_88-判断题-normalizer类当norm-inf-时-实现的功能与maxabsscale类一样。" tabindex="-1"><a class="header-anchor" href="#_88-判断题-normalizer类当norm-inf-时-实现的功能与maxabsscale类一样。"><span>88.(判断题) <p>Normalizer类当norm=&#39;inf&#39;时，实现的功能与MaxAbsScale类一样。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_89-单选题-在定义卷积层是-卷积核的通道数如何确定" tabindex="-1"><a class="header-anchor" href="#_89-单选题-在定义卷积层是-卷积核的通道数如何确定"><span>89.(单选题) <p>在定义卷积层是，卷积核的通道数如何确定？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>必须等于当前被卷积的数据的通道数</p></strong></li><li><p>由人工确定</p></li><li><p>等于3</p></li><li><p>等于输出数据的通道数</p></li></ul></li></ul><h4 id="_90-判断题-使用standardscaler变换以后-数据的取值范围变为-0-1-。" tabindex="-1"><a class="header-anchor" href="#_90-判断题-使用standardscaler变换以后-数据的取值范围变为-0-1-。"><span>90.(判断题) <p>使用StandardScaler变换以后，数据的取值范围变为(0,1)。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_91-单选题-卷积结果的通道数如何确定" tabindex="-1"><a class="header-anchor" href="#_91-单选题-卷积结果的通道数如何确定"><span>91.(单选题) <p>卷积结果的通道数如何确定？</p></span></a></h4><ul><li>选项: <ul><li><p>等于卷积核的通道数</p></li><li id="blue-msg"><strong><p>等于卷积核的数量</p></strong></li><li><p>等于当前被卷积的数据的通道数</p></li><li><p>等于3</p></li></ul></li></ul><h4 id="_92-单选题-针对输入是224x224x3的特征-使用11x11x3的卷积核-步长为4-填充为2-那么输出特征的空间尺寸为" tabindex="-1"><a class="header-anchor" href="#_92-单选题-针对输入是224x224x3的特征-使用11x11x3的卷积核-步长为4-填充为2-那么输出特征的空间尺寸为"><span>92.(单选题) <p>针对输入是224X224X3的特征，使用11X11X3的卷积核，步长为4，填充为2，那么输出特征的空间尺寸为？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>55X55</p></strong></li><li><p>224X224</p></li><li><p>112X112</p></li><li><p>234X234</p></li></ul></li></ul><h4 id="_93-单选题-连续使用三次3x3卷积-其感受野相当于多大" tabindex="-1"><a class="header-anchor" href="#_93-单选题-连续使用三次3x3卷积-其感受野相当于多大"><span>93.(单选题) <p>连续使用三次3X3卷积，其感受野相当于多大？</p></span></a></h4><ul><li>选项: <ul><li><p>3X3</p></li><li><p>5X5</p></li><li id="blue-msg"><strong><p>7X7</p></strong></li><li><p>9X9</p></li></ul></li></ul><h4 id="_94-判断题-vgg的特点是连续使用堆叠的3x3卷积核来扩大感受野。" tabindex="-1"><a class="header-anchor" href="#_94-判断题-vgg的特点是连续使用堆叠的3x3卷积核来扩大感受野。"><span>94.(判断题) <p>VGG的特点是连续使用堆叠的3X3卷积核来扩大感受野。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_95-判断题-1x1卷积核的作用相当于对特征在通道方向上加权求和。" tabindex="-1"><a class="header-anchor" href="#_95-判断题-1x1卷积核的作用相当于对特征在通道方向上加权求和。"><span>95.(判断题) <p>1X1卷积核的作用相当于对特征在通道方向上加权求和。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_96-判断题-resnet使用残差连接大大加深了卷积神经网络的深度。" tabindex="-1"><a class="header-anchor" href="#_96-判断题-resnet使用残差连接大大加深了卷积神经网络的深度。"><span>96.(判断题) <p>ResNet使用残差连接大大加深了卷积神经网络的深度。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_97-判断题-densenet通过特征重用-既大幅度减少了网络的参数量-又在一定程度上缓解了梯度消失问题的产生。" tabindex="-1"><a class="header-anchor" href="#_97-判断题-densenet通过特征重用-既大幅度减少了网络的参数量-又在一定程度上缓解了梯度消失问题的产生。"><span>97.(判断题) <p>DenseNet通过特征重用，既大幅度减少了网络的参数量，又在一定程度上缓解了梯度消失问题的产生。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h3 id="期末上机测试-数科22" tabindex="-1"><a class="header-anchor" href="#期末上机测试-数科22"><span>期末上机测试-数科22</span></a></h3><h4 id="_1-填空题-原始数据的样本数量为" tabindex="-1"><a class="header-anchor" href="#_1-填空题-原始数据的样本数量为"><span>1.(填空题) <p>原始数据的样本数量为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>10000</strong></li></ul></li></ul><h4 id="_2-填空题-原始数据的特征维度为" tabindex="-1"><a class="header-anchor" href="#_2-填空题-原始数据的特征维度为"><span>2.(填空题) <p>原始数据的特征维度为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>64</strong></li></ul></li></ul><h4 id="_3-填空题-特征的第1个维度的均值是-请四舍五入保留4位小数" tabindex="-1"><a class="header-anchor" href="#_3-填空题-特征的第1个维度的均值是-请四舍五入保留4位小数"><span>3.(填空题) <p>特征的第1个维度的均值是？（请四舍五入保留4位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.0081</strong></li></ul></li></ul><h4 id="_4-填空题-特征的第1个维度的标准差是-请四舍五入保留4位小数" tabindex="-1"><a class="header-anchor" href="#_4-填空题-特征的第1个维度的标准差是-请四舍五入保留4位小数"><span>4.(填空题) <p>特征的第1个维度的标准差是？（请四舍五入保留4位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.9992</strong></li></ul></li></ul><h4 id="_5-填空题-pca的目标维度为" tabindex="-1"><a class="header-anchor" href="#_5-填空题-pca的目标维度为"><span>5.(填空题) <p>PCA的目标维度为？</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>63</strong></li></ul></li></ul><h4 id="_6-填空题-pca的降维矩阵的第一个元素为-请四舍五入保留4位小数" tabindex="-1"><a class="header-anchor" href="#_6-填空题-pca的降维矩阵的第一个元素为-请四舍五入保留4位小数"><span>6.(填空题) <p>PCA的降维矩阵的第一个元素为？（请四舍五入保留4位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.0016</strong></li></ul></li></ul><h4 id="_7-填空题-模型在测试集上的准确率是-请四舍五入保留4位小数" tabindex="-1"><a class="header-anchor" href="#_7-填空题-模型在测试集上的准确率是-请四舍五入保留4位小数"><span>7.(填空题) <p>模型在测试集上的准确率是？（请四舍五入保留4位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.6373</strong></li></ul></li></ul><h4 id="_8-填空题-模型在测试集上的召回率是-请四舍五入保留4位小数" tabindex="-1"><a class="header-anchor" href="#_8-填空题-模型在测试集上的召回率是-请四舍五入保留4位小数"><span>8.(填空题) <p>模型在测试集上的召回率是？（请四舍五入保留4位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.6417</strong></li></ul></li></ul><h4 id="_9-填空题-模型在测试集上的精确率是-请四舍五入保留4位小数" tabindex="-1"><a class="header-anchor" href="#_9-填空题-模型在测试集上的精确率是-请四舍五入保留4位小数"><span>9.(填空题) <p>模型在测试集上的精确率是？（请四舍五入保留4位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.6882</strong></li></ul></li></ul><h4 id="_10-填空题-模型在测试集上的f1值是-请四舍五入保留4位小数" tabindex="-1"><a class="header-anchor" href="#_10-填空题-模型在测试集上的f1值是-请四舍五入保留4位小数"><span>10.(填空题) <p>模型在测试集上的F1值是？（请四舍五入保留4位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.6152</strong></li></ul></li></ul><h4 id="_11-填空题-第一个测试样本的预测类别为" tabindex="-1"><a class="header-anchor" href="#_11-填空题-第一个测试样本的预测类别为"><span>11.(填空题) <p>第一个测试样本的预测类别为？</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>1</strong></li></ul></li></ul><h4 id="_12-填空题-第二个测试样本的预测类别为" tabindex="-1"><a class="header-anchor" href="#_12-填空题-第二个测试样本的预测类别为"><span>12.(填空题) <p>第二个测试样本的预测类别为？</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>1</strong></li></ul></li></ul><h4 id="_13-填空题-第三个测试样本的预测类别为" tabindex="-1"><a class="header-anchor" href="#_13-填空题-第三个测试样本的预测类别为"><span>13.(填空题) <p>第三个测试样本的预测类别为？</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>1</strong></li></ul></li></ul><h3 id="分类阶段性测试一-分类" tabindex="-1"><a class="header-anchor" href="#分类阶段性测试一-分类"><span>分类阶段性测试一-分类</span></a></h3><h4 id="_1-多选题-机器学习三要素是" tabindex="-1"><a class="header-anchor" href="#_1-多选题-机器学习三要素是"><span>1.(多选题) <p>机器学习三要素是？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>模型</p></strong></li><li id="blue-msg"><strong><p>策略</p></strong></li><li id="blue-msg"><strong><p>算法</p></strong></li><li><p>样本</p></li></ul></li></ul><h4 id="_2-判断题-感知器算法的损失函数是误分类点的总数。" tabindex="-1"><a class="header-anchor" href="#_2-判断题-感知器算法的损失函数是误分类点的总数。"><span>2.(判断题) <p>感知器算法的损失函数是误分类点的总数。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_3-填空题-sklearn提供的感知器类是perceptron-该类实例化的时候一个重要的参数是eta0-请问该参数表示什么" tabindex="-1"><a class="header-anchor" href="#_3-填空题-sklearn提供的感知器类是perceptron-该类实例化的时候一个重要的参数是eta0-请问该参数表示什么"><span>3.(填空题) <p>sklearn提供的感知器类是Perceptron，该类实例化的时候一个重要的参数是eta0，请问该参数表示什么？</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>学习率</strong></li></ul></li></ul><h4 id="_4-多选题-下述指标常用来评价分类模型的有哪些" tabindex="-1"><a class="header-anchor" href="#_4-多选题-下述指标常用来评价分类模型的有哪些"><span>4.(多选题) <p>下述指标常用来评价分类模型的有哪些？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>准确率（accuracy）</p></strong></li><li id="blue-msg"><strong><p>精确率（precision）</p></strong></li><li id="blue-msg"><strong><p>召回率（recall）</p></strong></li><li id="blue-msg"><strong><p>F1-值（F1-score）</p></strong></li><li><p>均方误差</p></li></ul></li></ul><h4 id="_5-段落说明-现有10个样本-6个阳性-positive-4个阴性-negative-。模型分别将2个阳性和1个阴性样本预测错误-其余样本均预测正确。请根据该数据-完成下述四个题目。" tabindex="-1"><a class="header-anchor" href="#_5-段落说明-现有10个样本-6个阳性-positive-4个阴性-negative-。模型分别将2个阳性和1个阴性样本预测错误-其余样本均预测正确。请根据该数据-完成下述四个题目。"><span>5.(段落说明) <p>现有10个样本，6个阳性（positive），4个阴性（negative）。模型分别将2个阳性和1个阴性样本预测错误，其余样本均预测正确。请根据该数据，完成下述四个题目。</p></span></a></h4><ul><li>答案: <ul><li>暂无答案</li></ul></li></ul><h4 id="_6-填空题-模型的准确率-accuracy-是多少-保留两位小数" tabindex="-1"><a class="header-anchor" href="#_6-填空题-模型的准确率-accuracy-是多少-保留两位小数"><span>6.(填空题) <p>模型的准确率（accuracy）是多少？（保留两位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.70</strong></li></ul></li></ul><h4 id="_7-填空题-模型的精确率-precision-是多少-保留两位小数" tabindex="-1"><a class="header-anchor" href="#_7-填空题-模型的精确率-precision-是多少-保留两位小数"><span>7.(填空题) <p>模型的精确率（precision）是多少？（保留两位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.80</strong></li></ul></li></ul><h4 id="_8-填空题-模型的召回率-recall-是多少-保留两位小数" tabindex="-1"><a class="header-anchor" href="#_8-填空题-模型的召回率-recall-是多少-保留两位小数"><span>8.(填空题) <p>模型的召回率（recall）是多少？（保留两位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.67</strong></li></ul></li></ul><h4 id="_9-填空题-f1-值-f1-score-是多少-保留两位小数" tabindex="-1"><a class="header-anchor" href="#_9-填空题-f1-值-f1-score-是多少-保留两位小数"><span>9.(填空题) <p>F1-值（F1-score）是多少？（保留两位小数）</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.73</strong></li></ul></li></ul><h4 id="_10-单选题-点击率的预测是一个数据比例不平衡问题-比如训练集中样本呈阴性的比例为99-阳性的比例是1-如果我们用这种数据建立模型并使得训练集的准确率高达99-。下列说法正确的是" tabindex="-1"><a class="header-anchor" href="#_10-单选题-点击率的预测是一个数据比例不平衡问题-比如训练集中样本呈阴性的比例为99-阳性的比例是1-如果我们用这种数据建立模型并使得训练集的准确率高达99-。下列说法正确的是"><span>10.(单选题) <p>点击率的预测是一个数据比例不平衡问题（比如训练集中样本呈阴性的比例为99%，阳性的比例是1%），如果我们用这种数据建立模型并使得训练集的准确率高达99%。下列说法正确的是</p></span></a></h4><ul><li>选项: <ul><li>模型的准确率非常高，我们不需要进一步探索</li><li><p>不能确定模型是否好，应该进一步探讨精确率（precision），如果精确率高，说明模型好。</p></li><li><p>训练样本中阳性和阴性样本的比例不影响模型的性能。</p></li><li id="blue-msg"><strong><p>不能确定模型是否好，应该进一步探讨召回率（recall），如果召回率低，说明模型不好，需要重新考虑。</p></strong></li></ul></li></ul><h4 id="_11-单选题-下列关于支持向量机模型叙述错误的是" tabindex="-1"><a class="header-anchor" href="#_11-单选题-下列关于支持向量机模型叙述错误的是"><span>11.(单选题) <p>下列关于支持向量机模型叙述错误的是？</p></span></a></h4><ul><li>选项: <ul><li><p>对偶问题的解中非零的alpha对应的样本是支持向量。</p></li><li id="blue-msg"><strong><p>将不是支持向量的样本去掉后，使用相同参数重新求得的超平面可能会不同。</p></strong></li><li><p>当惩罚系数C趋于无穷大时，软间隔最大化问题会退化为硬间隔最大化问题。</p></li><li><p>惩罚系数C越小，间隔越大，模型的泛化性能越差。</p></li></ul></li></ul><h4 id="_12-单选题-支持向量机的损失函数是" tabindex="-1"><a class="header-anchor" href="#_12-单选题-支持向量机的损失函数是"><span>12.(单选题) <p>支持向量机的损失函数是？</p></span></a></h4><ul><li>选项: <ul><li><p>0-1损失函数</p></li><li><p>交叉熵损失函数</p></li><li><p>KL-散度</p></li><li id="blue-msg"><strong><p>合页损失函数</p></strong></li></ul></li></ul><h4 id="_13-判断题-线性不可分问题不能使用支持向量机模型求解。" tabindex="-1"><a class="header-anchor" href="#_13-判断题-线性不可分问题不能使用支持向量机模型求解。"><span>13.(判断题) <p>线性不可分问题不能使用支持向量机模型求解。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_14-单选题-sklearn中用支持向量机分类的类名是svc-该类默认使用的核是" tabindex="-1"><a class="header-anchor" href="#_14-单选题-sklearn中用支持向量机分类的类名是svc-该类默认使用的核是"><span>14.(单选题) <p>sklearn中用支持向量机分类的类名是SVC，该类默认使用的核是？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>径向基核函数</p></strong></li><li><p>多项式核函数</p></li><li><p>线性核函数</p></li><li><p>Sigmoid核函数</p></li></ul></li></ul><h4 id="_15-单选题-下列关于多类分类问题-叙述错误的是" tabindex="-1"><a class="header-anchor" href="#_15-单选题-下列关于多类分类问题-叙述错误的是"><span>15.(单选题) <p>下列关于多类分类问题，叙述错误的是</p></span></a></h4><ul><li>选项: <ul><li><p>多类分类问题可以转化为二分类问题</p></li><li><p>one-versus-rest方法可以将多类分类问题转化为二分类问题，但是存在训练样本不平衡的问题。</p></li><li id="blue-msg"><strong><p>one-versus-one方法可以将多类分类问题转化为二分类问题，与one-versus-rest方法的计算量相当</p></strong></li><li><p>one-versus-one方法通常使用投票原则预测分类结果。</p></li></ul></li></ul><h4 id="_16-单选题-下列算法属于生成式模型的是" tabindex="-1"><a class="header-anchor" href="#_16-单选题-下列算法属于生成式模型的是"><span>16.(单选题) <p>下列算法属于生成式模型的是？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>朴素贝叶斯</p></strong></li><li><p>支持向量机</p></li><li><p>感知器算法</p></li><li><p>决策树</p></li></ul></li></ul><h4 id="_17-单选题-下列关于朴素贝叶斯叙述错误的是" tabindex="-1"><a class="header-anchor" href="#_17-单选题-下列关于朴素贝叶斯叙述错误的是"><span>17.(单选题) <p>下列关于朴素贝叶斯叙述错误的是？</p></span></a></h4><ul><li>选项: <ul><li><p>朴素贝叶斯模型的核心假设是“在类别已知的情况下，特征条件独立”。</p></li><li id="blue-msg"><strong><p>朴素贝叶斯模型无法解决连续特征的分类问题。</p></strong></li><li><p>朴素贝叶斯常用于文本分类。</p></li><li><p>拉普拉斯平滑可以有效解决零概率问题。</p></li></ul></li></ul><h4 id="_18-单选题-sklearn中用于分类任务的k-近邻算法的类是kneighborclassifier-下述那个参数是算法中的k" tabindex="-1"><a class="header-anchor" href="#_18-单选题-sklearn中用于分类任务的k-近邻算法的类是kneighborclassifier-下述那个参数是算法中的k"><span>18.(单选题) <p>sklearn中用于分类任务的K-近邻算法的类是KNeighborClassifier，下述那个参数是算法中的K？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>n_neighbors</p></strong></li><li><p>metric</p></li><li><p>p</p></li><li><p>weights</p></li></ul></li></ul><h4 id="_19-判断题-k-近邻算法中的超参数k太大和太小对模型都有影响-不同的问题应该选择合适的k。" tabindex="-1"><a class="header-anchor" href="#_19-判断题-k-近邻算法中的超参数k太大和太小对模型都有影响-不同的问题应该选择合适的k。"><span>19.(判断题) <p>K-近邻算法中的超参数K太大和太小对模型都有影响，不同的问题应该选择合适的K。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_20-判断题-kd-树中的k和k-近邻中的k都是表示满足特定条件的样本个数。" tabindex="-1"><a class="header-anchor" href="#_20-判断题-kd-树中的k和k-近邻中的k都是表示满足特定条件的样本个数。"><span>20.(判断题) <p>KD-树中的K和K-近邻中的K都是表示满足特定条件的样本个数。</p></span></a></h4><ul><li>答案: <ul><li>对</li><li id="blue-msg"><strong>错</strong></li></ul></li></ul><h4 id="_21-判断题-kd-树和ball-树都是为了提升k-近邻算法查找k个近邻样本的效率而设计的数据结构。与暴力搜索相比-它们在特征维度较小时有明显优势。" tabindex="-1"><a class="header-anchor" href="#_21-判断题-kd-树和ball-树都是为了提升k-近邻算法查找k个近邻样本的效率而设计的数据结构。与暴力搜索相比-它们在特征维度较小时有明显优势。"><span>21.(判断题) <p>KD-树和Ball-树都是为了提升K-近邻算法查找K个近邻样本的效率而设计的数据结构。与暴力搜索相比，它们在特征维度较小时有明显优势。</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>对</strong></li><li>错</li></ul></li></ul><h4 id="_22-多选题-下列选项中关于k-近邻算法叙述正确的有" tabindex="-1"><a class="header-anchor" href="#_22-多选题-下列选项中关于k-近邻算法叙述正确的有"><span>22.(多选题) <p>下列选项中关于K-近邻算法叙述正确的有</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>K-近邻算法没有明显的训练过程，计算量主要体现在测试阶段。</p></strong></li><li><p>用K-近邻算法分类，预测速度与训练样本多少无关，只与测试样本的数量有关系。</p></li><li><p>K-近邻算法的运算速度与特征的维度无关。</p></li><li id="blue-msg"><strong><p>在使用sklearn中的K-近邻算法时，如果选择了KD-树或Ball-树等数据结构，fit阶段主要用来构建相应的数据结构。</p></strong></li></ul></li></ul><h4 id="_23-多选题-关于决策树-下列说法正确的有" tabindex="-1"><a class="header-anchor" href="#_23-多选题-关于决策树-下列说法正确的有"><span>23.(多选题) <p>关于决策树，下列说法正确的有</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>构建决策树的关键是确定划分属性。</p></strong></li><li><p>决策树越深模型的分类效果越好。</p></li><li id="blue-msg"><strong><p>如果使用信息增益确定最优划分属性，应该选择信息增益大的属性。</p></strong></li><li><p>如果使用基尼指数确定最优划分属性，应该选择基尼指数大的属性。</p></li></ul></li></ul><h4 id="_24-单选题-用决策树分类时-如果训练集规模很大-那么下面哪种方式比较合理" tabindex="-1"><a class="header-anchor" href="#_24-单选题-用决策树分类时-如果训练集规模很大-那么下面哪种方式比较合理"><span>24.(单选题) <p>用决策树分类时，如果训练集规模很大，那么下面哪种方式比较合理？</p></span></a></h4><ul><li>选项: <ul><li><p>降低特征的维度</p></li><li><ol start="2"><li>增加学习率</li></ol></li><li id="blue-msg"><strong><p>3. 减少树的深度</p></strong></li><li><p>挑选少量样本来训练</p></li></ul></li></ul><h4 id="_25-多选题-决策树剪枝的主要目的是" tabindex="-1"><a class="header-anchor" href="#_25-多选题-决策树剪枝的主要目的是"><span>25.(多选题) <p>决策树剪枝的主要目的是？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>降低过拟合风险</p></strong></li><li><p>降低欠拟合风险</p></li><li><p>提高模型在训练集的准确率</p></li><li id="blue-msg"><strong><p>提高模型的泛化能力</p></strong></li></ul></li></ul><h4 id="_26-多选题-经典决策树有id3-c4-5-cart等-下列选项中关于这些算法叙述正确的有" tabindex="-1"><a class="header-anchor" href="#_26-多选题-经典决策树有id3-c4-5-cart等-下列选项中关于这些算法叙述正确的有"><span>26.(多选题) <p>经典决策树有ID3，C4.5，CART等，下列选项中关于这些算法叙述正确的有</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>ID3没有考虑连续特征。</p></strong></li><li id="blue-msg"><strong><p>ID3使用信息增益确定划分属性。</p></strong></li><li id="blue-msg"><strong><p>C4.5使用增益率确定划分属性。</p></strong></li><li id="blue-msg"><strong><p>CART生成的树是二叉树，使用了基尼指数确定划分属性。</p></strong></li><li id="blue-msg"><strong><p>C4.5和CART都可以处理连续属性，都考虑了剪枝，都考虑了缺失值的处理。</p></strong></li><li><p>构建相同深度的决策树，CART比C4.5的运算量大。</p></li></ul></li></ul><h4 id="_27-多选题-下列选项中-哪些算法使用串行策略-通过提升的方式-由若干弱分类器构建出强分类器" tabindex="-1"><a class="header-anchor" href="#_27-多选题-下列选项中-哪些算法使用串行策略-通过提升的方式-由若干弱分类器构建出强分类器"><span>27.(多选题) <p>下列选项中，哪些算法使用串行策略，通过提升的方式，由若干弱分类器构建出强分类器？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>AdaBoost</p></strong></li><li id="blue-msg"><strong><p>梯度提升树</p></strong></li><li><p>决策树</p></li><li><p>Bagging</p></li></ul></li></ul><h4 id="_28-多选题-下列选项中-关于adaboost算法描述正确的有" tabindex="-1"><a class="header-anchor" href="#_28-多选题-下列选项中-关于adaboost算法描述正确的有"><span>28.(多选题) <p>下列选项中，关于AdaBoost算法描述正确的有？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>AdBoost算法通过调整样本的分布，使得当前的弱分类器会优先将分布值大的样本分对。</p></strong></li><li id="blue-msg"><strong><p>AdaBoost算法是向前分步算法的特例。</p></strong></li><li id="blue-msg"><strong><p>在sklearn中，用于分类的AdaBoost算法对应的类是AdaBoostClassifier，其中参数n_estimators是弱分类器个数。</p></strong></li><li><p>AdaBoost算法很好地体现了好而不同的策略。</p></li></ul></li></ul><h4 id="_29-多选题-下列选项中-关于bagging-叙述正确的有" tabindex="-1"><a class="header-anchor" href="#_29-多选题-下列选项中-关于bagging-叙述正确的有"><span>29.(多选题) <p>下列选项中，关于Bagging，叙述正确的有？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>在测试阶段，Bagging在学习到的基学习器中通过投票规则确定最终分类结果。</p></strong></li><li id="blue-msg"><strong><p>Bagging通过Bootstrap重采样的方式实现样本扰动，进而使各基学习器具有差异性。</p></strong></li><li id="blue-msg"><strong><p>在sklearn中，用于分类的Bagging算法对应的类是BaggingClassifier，其中参数n_estimators是基学习器的个数。</p></strong></li><li><p>Bootstrap重采样保证了所有训练样本都将被用来训练某个基学习器。</p></li></ul></li></ul><h4 id="_30-单选题-bootstrap-数据的含义是" tabindex="-1"><a class="header-anchor" href="#_30-单选题-bootstrap-数据的含义是"><span>30.(单选题) <p>bootstrap 数据的含义是：</p></span></a></h4><ul><li>选项: <ul><li><p>有放回的从整体M中抽样m个特征</p></li><li><p>无放回的从整体M中抽样m个特征</p></li><li id="blue-msg"><strong><p>有放回的从整体N中抽样n个样本</p></strong></li><li><p>无放回的从整体N中抽样n个样本</p></li></ul></li></ul><h4 id="_31-多选题-下列选项中-关于随机森林叙述正确的有" tabindex="-1"><a class="header-anchor" href="#_31-多选题-下列选项中-关于随机森林叙述正确的有"><span>31.(多选题) <p>下列选项中，关于随机森林叙述正确的有？</p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>随机森林通过样本扰动和属性扰动使每棵决策树具有差异性。</p></strong></li><li id="blue-msg"><strong><p>大多数情况下，随机森林的性能优于Bagging。</p></strong></li><li><p>随机森林很好地使用了分而治之的策略。</p></li><li><p>构建随机森林时，随机选取属性个数的参数k无关紧要，该参数的大小对模型的性能影响不大。</p></li></ul></li></ul><h4 id="_32-段落说明-现根据以下数据要构建是否放贷的决策树。在此背景下-完成后续题目-42-51-。结果保留两位小数。" tabindex="-1"><a class="header-anchor" href="#_32-段落说明-现根据以下数据要构建是否放贷的决策树。在此背景下-完成后续题目-42-51-。结果保留两位小数。"><span>32.(段落说明) <p>现根据以下数据要构建是否放贷的决策树。在此背景下，完成后续题目（42-51）。结果保留两位小数。</p></span></a></h4><p> </p><table style="border-collapse:collapse;width:99.6425%;height:171px;" border="1"><tbody><tr style="height:19px;"><td style="width:19.6644%;height:19px;">编号</td><td style="width:19.6644%;height:19px;">有工作</td><td style="width:19.6644%;height:19px;">有房产</td><td style="width:19.6644%;height:19px;">信贷情况</td><td style="width:19.7765%;height:19px;">放贷</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">1</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">好</td><td style="width:19.7765%;height:19px;">是</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">2</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">非常好</td><td style="width:19.7765%;height:19px;">是</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">3</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">非常好</td><td style="width:19.7765%;height:19px;">是</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">4</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">好</td><td style="width:19.7765%;height:19px;">是</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">5</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">一般</td><td style="width:19.7765%;height:19px;">否</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">6</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">好</td><td style="width:19.7765%;height:19px;">否</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">7</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">一般</td><td style="width:19.7765%;height:19px;">否</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">8</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">一般</td><td style="width:19.7765%;height:19px;">否</td></tr></tbody></table><ul><li>答案: <ul><li>暂无答案</li></ul></li></ul><h4 id="_33-填空题-样本集的信息熵为" tabindex="-1"><a class="header-anchor" href="#_33-填空题-样本集的信息熵为"><span>33.(填空题) <p>样本集的信息熵为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>1.00</p></strong></li></ul></li></ul><h4 id="_34-填空题-属性-有工作-的取值为-是-的样本集的熵为" tabindex="-1"><a class="header-anchor" href="#_34-填空题-属性-有工作-的取值为-是-的样本集的熵为"><span>34.(填空题) <p>属性“有工作”的取值为“是”的样本集的熵为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.92</strong></li></ul></li></ul><h4 id="_35-填空题-属性-有工作-的取值为-否-的样本集的熵为" tabindex="-1"><a class="header-anchor" href="#_35-填空题-属性-有工作-的取值为-否-的样本集的熵为"><span>35.(填空题) <p>属性“有工作”的取值为“否”的样本集的熵为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.97</strong></li></ul></li></ul><h4 id="_36-填空题-属性-有工作-的条件熵为" tabindex="-1"><a class="header-anchor" href="#_36-填空题-属性-有工作-的条件熵为"><span>36.(填空题) <p>属性“有工作”的条件熵为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.95</strong></li></ul></li></ul><h4 id="_37-填空题-属性-有工作-的信息增益为" tabindex="-1"><a class="header-anchor" href="#_37-填空题-属性-有工作-的信息增益为"><span>37.(填空题) <p>属性“有工作”的信息增益为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.05</strong></li></ul></li></ul><h4 id="_38-填空题-属性-有房产-的条件熵为" tabindex="-1"><a class="header-anchor" href="#_38-填空题-属性-有房产-的条件熵为"><span>38.(填空题) <p>属性“有房产”的条件熵为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.69</strong></li></ul></li></ul><h4 id="_39-填空题-属性-有房产-的信息增益为" tabindex="-1"><a class="header-anchor" href="#_39-填空题-属性-有房产-的信息增益为"><span>39.(填空题) <p>属性“有房产”的信息增益为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.31</strong></li></ul></li></ul><h4 id="_40-填空题-属性-信贷情况-的条件熵为" tabindex="-1"><a class="header-anchor" href="#_40-填空题-属性-信贷情况-的条件熵为"><span>40.(填空题) <p>属性“信贷情况”的条件熵为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.34</strong></li></ul></li></ul><h4 id="_41-填空题-属性-信贷情况-的信息增益为" tabindex="-1"><a class="header-anchor" href="#_41-填空题-属性-信贷情况-的信息增益为"><span>41.(填空题) <p>属性“信贷情况”的信息增益为</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>0.66</strong></li></ul></li></ul><h4 id="_42-填空题-根节点的划分属性是" tabindex="-1"><a class="header-anchor" href="#_42-填空题-根节点的划分属性是"><span>42.(填空题) <p>根节点的划分属性是</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong>信贷情况</strong></li></ul></li></ul><h4 id="_43-段落说明-现根据以下数据-使用朴素贝叶斯预测新样本-是-是-好-的放贷情况。请完成下述题目-53-61-结果保留两位小数。" tabindex="-1"><a class="header-anchor" href="#_43-段落说明-现根据以下数据-使用朴素贝叶斯预测新样本-是-是-好-的放贷情况。请完成下述题目-53-61-结果保留两位小数。"><span>43.(段落说明) <p>现根据以下数据，使用朴素贝叶斯预测新样本（是，是，好）的放贷情况。请完成下述题目（53-61），结果保留两位小数。</p></span></a></h4><p> </p><table style="border-collapse:collapse;width:99.6425%;height:171px;" border="1"><tbody><tr style="height:19px;"><td style="width:19.6644%;height:19px;">编号</td><td style="width:19.6644%;height:19px;">有工作</td><td style="width:19.6644%;height:19px;">有房产</td><td style="width:19.6644%;height:19px;">信贷情况</td><td style="width:19.7765%;height:19px;">放贷</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">1</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">好</td><td style="width:19.7765%;height:19px;">是</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">2</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">非常好</td><td style="width:19.7765%;height:19px;">是</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">3</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">非常好</td><td style="width:19.7765%;height:19px;">是</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">4</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">好</td><td style="width:19.7765%;height:19px;">是</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">5</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">一般</td><td style="width:19.7765%;height:19px;">否</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">6</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">好</td><td style="width:19.7765%;height:19px;">否</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">7</td><td style="width:19.6644%;height:19px;">是</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">一般</td><td style="width:19.7765%;height:19px;">否</td></tr><tr style="height:19px;"><td style="width:19.6644%;height:19px;">8</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">否</td><td style="width:19.6644%;height:19px;">一般</td><td style="width:19.7765%;height:19px;">否</td></tr></tbody></table><p> </p><ul><li>答案: <ul><li>暂无答案</li></ul></li></ul><h4 id="_44-填空题-p-y-是" tabindex="-1"><a class="header-anchor" href="#_44-填空题-p-y-是"><span>44.(填空题) <p>P(Y=是)=？</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>0.50</p></strong></li></ul></li></ul><h4 id="_45-填空题-p-有工作-是-y-是" tabindex="-1"><a class="header-anchor" href="#_45-填空题-p-有工作-是-y-是"><span>45.(填空题) <p>P(有工作=是|Y=是)=？</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>0.50</p></strong></li></ul></li></ul><h4 id="_46-填空题-p-有房产-是-y-是" tabindex="-1"><a class="header-anchor" href="#_46-填空题-p-有房产-是-y-是"><span>46.(填空题) <p><span style="display:inline !important;float:none;background-color:#ffffff;color:#000000;font-family:Roboto,Helvetica,Arial,sans-serif;font-size:inherit;font-size-adjust:none;font-stretch:inherit;font-style:inherit;font-variant:inherit;font-weight:400;letter-spacing:normal;line-height:inherit;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;">P(有房产=是|Y=是)=？</span></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>0.50</p></strong></li></ul></li></ul><h4 id="_47-填空题-p-信贷情况-好-y-是" tabindex="-1"><a class="header-anchor" href="#_47-填空题-p-信贷情况-好-y-是"><span>47.(填空题) <p><span style="display:inline !important;float:none;background-color:#ffffff;color:#000000;font-family:Roboto,Helvetica,Arial,sans-serif;font-size:inherit;font-size-adjust:none;font-stretch:inherit;font-style:inherit;font-variant:inherit;font-weight:400;letter-spacing:normal;line-height:inherit;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;">P(信贷情况=好|Y=是)=？</span></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>0.50</p></strong></li></ul></li></ul><h4 id="_48-填空题-p-y-否" tabindex="-1"><a class="header-anchor" href="#_48-填空题-p-y-否"><span>48.(填空题) <p><span style="display:inline !important;float:none;background-color:#ffffff;color:#000000;font-family:Roboto,Helvetica,Arial,sans-serif;font-size:inherit;font-size-adjust:none;font-stretch:inherit;font-style:inherit;font-variant:inherit;font-weight:400;letter-spacing:normal;line-height:inherit;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;">P(Y=否)=？</span></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>0.50</p></strong></li></ul></li></ul><h4 id="_49-填空题-p-有工作-是-y-否" tabindex="-1"><a class="header-anchor" href="#_49-填空题-p-有工作-是-y-否"><span>49.(填空题) <p><span style="display:inline !important;float:none;background-color:#ffffff;color:#000000;font-family:Roboto,Helvetica,Arial,sans-serif;font-size:inherit;font-size-adjust:none;font-stretch:inherit;font-style:inherit;font-variant:inherit;font-weight:400;letter-spacing:normal;line-height:inherit;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;">P(有工作=是|Y=否)=？</span></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>0.25</p></strong></li></ul></li></ul><h4 id="_50-填空题-p-有房产-是-y-否" tabindex="-1"><a class="header-anchor" href="#_50-填空题-p-有房产-是-y-否"><span>50.(填空题) <p><span style="display:inline !important;float:none;background-color:#ffffff;color:#000000;font-family:Roboto,Helvetica,Arial,sans-serif;font-size:inherit;font-size-adjust:none;font-stretch:inherit;font-style:inherit;font-variant:inherit;font-weight:400;letter-spacing:normal;line-height:inherit;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;">P(有房产=是|Y=否)=？</span></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>0.00</p></strong></li></ul></li></ul><h4 id="_51-填空题-p-信贷情况-好-y-否" tabindex="-1"><a class="header-anchor" href="#_51-填空题-p-信贷情况-好-y-否"><span>51.(填空题) <p><span style="display:inline !important;float:none;background-color:#ffffff;color:#000000;font-family:Roboto,Helvetica,Arial,sans-serif;font-size:inherit;font-size-adjust:none;font-stretch:inherit;font-style:inherit;font-variant:inherit;font-weight:400;letter-spacing:normal;line-height:inherit;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;">P(信贷情况=好|Y=否)=？</span></p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>0.25</p></strong></li></ul></li></ul><h4 id="_52-单选题-根据上述计算结果-样本-是-是-好-是否放贷" tabindex="-1"><a class="header-anchor" href="#_52-单选题-根据上述计算结果-样本-是-是-好-是否放贷"><span>52.(单选题) <p>根据上述计算结果，<span style="display:inline !important;float:none;background-color:#ffffff;color:#000000;font-family:Roboto,Helvetica,Arial,sans-serif;font-size:inherit;font-size-adjust:none;font-stretch:inherit;font-style:inherit;font-variant:inherit;font-weight:400;letter-spacing:normal;line-height:inherit;orphans:2;text-align:left;text-decoration:none;text-indent:0px;text-transform:none;-webkit-text-stroke-width:0px;white-space:normal;word-spacing:0px;">样本（是，是，好）是否放贷？</span></p></span></a></h4><ul><li>选项: <ul><li id="blue-msg"><strong><p>是</p></strong></li><li><p>否</p></li><li><p>无法确定</p></li></ul></li></ul><h4 id="_53-段落说明-现有如下样本" tabindex="-1"><a class="header-anchor" href="#_53-段落说明-现有如下样本"><span>53.(段落说明) <p>现有如下样本：</p></span></a></h4><table style="border-collapse:collapse;width:16.0795%;height:105px;" border="1"><tbody><tr style="height:21px;"><td style="width:33.4507%;height:21px;">x1</td><td style="width:33.4507%;height:21px;">x2</td><td style="width:33.4507%;height:21px;">y</td></tr><tr style="height:21px;"><td style="width:33.4507%;height:21px;">0</td><td style="width:33.4507%;height:21px;">1</td><td style="width:33.4507%;height:21px;">+1</td></tr><tr style="height:21px;"><td style="width:33.4507%;height:21px;">0</td><td style="width:33.4507%;height:21px;">2</td><td style="width:33.4507%;height:21px;">+1</td></tr><tr style="height:21px;"><td style="width:33.4507%;height:21px;">1</td><td style="width:33.4507%;height:21px;">0</td><td style="width:33.4507%;height:21px;">-1</td></tr><tr style="height:21px;"><td style="width:33.4507%;height:21px;">2</td><td style="width:33.4507%;height:21px;">0</td><td style="width:33.4507%;height:21px;">-1</td></tr></tbody></table><p>使用SVM得到分类超平面：w1x1+w2x2+b=0.</p><p>请完成下列问题（63-66）。结果保留两位小数。</p><ul><li>答案: <ul><li>暂无答案</li></ul></li></ul><h4 id="_54-填空题-w1" tabindex="-1"><a class="header-anchor" href="#_54-填空题-w1"><span>54.(填空题) <p>w1=?</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>-1.00</p></strong></li></ul></li></ul><h4 id="_55-填空题-w2" tabindex="-1"><a class="header-anchor" href="#_55-填空题-w2"><span>55.(填空题) <p>w2=?</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>1.00</p></strong></li></ul></li></ul><h4 id="_56-填空题-b" tabindex="-1"><a class="header-anchor" href="#_56-填空题-b"><span>56.(填空题) <p>b=?</p></span></a></h4><ul><li>答案: <ul><li id="blue-msg"><strong><p>0.00</p></strong></li></ul></li></ul><h4 id="_57-单选题-利用上述模型进行分类-样本-2-1-的分类结果是" tabindex="-1"><a class="header-anchor" href="#_57-单选题-利用上述模型进行分类-样本-2-1-的分类结果是"><span>57.(单选题) <p>利用上述模型进行分类，样本(2,1)的分类结果是？</p></span></a></h4><ul><li>选项: <ul><li><p>+1</p></li><li id="blue-msg"><strong><p>-1</p></strong></li><li><p>无法确定。</p></li></ul></li></ul>',181)]))}const d=a(e,[["render",r]]),g=JSON.parse('{"path":"/art/other/final_jiqixuexi.html","title":"机器学习选择题","lang":"zh-CN","frontmatter":{"title":"机器学习选择题","date":"2025-06-17T00:00:00.000Z","icon":"earth-americas","category":["期末考复习"],"tag":["机器学习"],"description":"期末随堂测试-数科22级 1.(判断题) 使用k-means算法聚类，算法执行过程中有可能出现空簇。 答案: 对 错 2.(判断题) 基于密度的聚类方法DBSCAN无需指定簇的个数。 答案: 对 错 3.(判断题) 使用基于密度的聚类方法DBSCAN后，每个样本都会归到某个簇中。 答案: 对 错 4.(判断题) 使用基于凝聚的层次聚类算法AGNES聚类...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"机器学习选择题\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-06-17T00:00:00.000Z\\",\\"dateModified\\":\\"2025-06-17T09:36:40.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"KurimulaAiri\\",\\"url\\":\\"https://github.com/KurimulaAiri\\"}]}"],["meta",{"property":"og:url","content":"https://md.s1r0ko.top/art/other/final_jiqixuexi.html"}],["meta",{"property":"og:site_name","content":"博客与资料库"}],["meta",{"property":"og:title","content":"机器学习选择题"}],["meta",{"property":"og:description","content":"期末随堂测试-数科22级 1.(判断题) 使用k-means算法聚类，算法执行过程中有可能出现空簇。 答案: 对 错 2.(判断题) 基于密度的聚类方法DBSCAN无需指定簇的个数。 答案: 对 错 3.(判断题) 使用基于密度的聚类方法DBSCAN后，每个样本都会归到某个簇中。 答案: 对 错 4.(判断题) 使用基于凝聚的层次聚类算法AGNES聚类..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-06-17T09:36:40.000Z"}],["meta",{"property":"article:tag","content":"机器学习"}],["meta",{"property":"article:published_time","content":"2025-06-17T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-06-17T09:36:40.000Z"}]]},"git":{"createdTime":1750153000000,"updatedTime":1750153000000,"contributors":[{"name":"KurimulaAiri","username":"KurimulaAiri","email":"1095370199@qq.com","commits":1,"url":"https://github.com/KurimulaAiri"}]},"readingTime":{"minutes":35.16,"words":10547},"filePathRelative":"art/other/final_jiqixuexi.md","excerpt":"<h3>期末随堂测试-数科22级</h3>\\n<h4>1.(判断题) <p>使用k-means算法聚类，算法执行过程中有可能出现空簇。</p></h4>\\n<ul>\\n<li>答案:\\n<ul>\\n<li id=\\"blue-msg\\"><strong>对</strong></li>\\n<li>错</li>\\n</ul>\\n</li>\\n</ul>\\n<h4>2.(判断题) <p>基于密度的聚类方法DBSCAN无需指定簇的个数。</p></h4>\\n<ul>\\n<li>答案:\\n<ul>\\n<li id=\\"blue-msg\\"><strong>对</strong></li>\\n<li>错</li>\\n</ul>\\n</li>\\n</ul>","autoDesc":true}');export{d as comp,g as data};
